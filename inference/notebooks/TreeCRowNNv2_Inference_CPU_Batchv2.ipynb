{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a3fb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "    Parameters\n",
    "        ----------\n",
    "        img_path : file path to .tif file\n",
    "            Location of image for inference 3-band (RGB) and 10cm spatial resolution\n",
    "        out_path : folder path \n",
    "            Location where model output will be written \n",
    "        site : str\n",
    "            Name to be given to model output \n",
    "  \n",
    "        tile_size : int\n",
    "            Value identifying desired forest stand size \n",
    "            E.G. TreeCRowNN accepts tiles with size 128, either use this or padding to achieve correct tile dimensions\n",
    "        patch_size : int\n",
    "            Value identifying the desired dimensions of extracted tiles\n",
    "            E.G. A value of 0 should be used for tiles with dimension 128pix X 128pix\n",
    "        padding : int\n",
    "            Value identifying the desired amount of zero padding to be added to tiles to reach dims 128p X 128p\n",
    "        batch_size : int\n",
    "            Size of batch to be sent to model for inference\n",
    "        minval : int\n",
    "            minimum data value of input image\n",
    "        maxval : int\n",
    "            maximum data value of input image\n",
    "            \n",
    "        generate_heatmap : bool\n",
    "            enter True to generate activation map in addition to FSD map\n",
    "            if True, processing time per stand will increase ~4x\n",
    "        normalize_heatmap : str\n",
    "            enter \"local\", \"global\", or \"none\"\n",
    "            if local, heatmap will be normalized per stand (useful to check for border issues)\n",
    "            if global, heatmap will be normalized for full input image (useful to check for image trends)\n",
    "            if none, no normalization will be applied\n",
    "            \n",
    "    Returns\n",
    "        -------\n",
    "        Array with predictions entered as integers, this array saved to .tif file in out_path location\n",
    "        List of predictions\n",
    "        Inference processing time in seconds\n",
    "        \n",
    "        Output will not be georeferenced, please use GDAL script to transfer metadata for use in a GIS\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f12ecab",
   "metadata": {},
   "source": [
    "## Set Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a2df03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = r'E:/MtPolley_Project/4_GIS/for_CNN/ortho/2023_treecounting/2019_ortho/2019_ort_4inf.tif'\n",
    "#img_path = r'E:/MtPolley_Project/4_GIS/for_CNN/ortho/2023_treecounting/2019_ortho/2019_ort_4inf_small2.tif'\n",
    "#img_path = r'E:/MtPolley_Project/4_GIS/for_CNN/ortho/2023_treecounting/2019_mine_site/MtP_Mine_clip_small.tif'\n",
    "#img_path = r'F:/MtPolley/tree_counting/10cm_Resamples/2022_USherbrooke_QCNL/Site_20_10cm.tif'\n",
    "#img_path = r'F:/MtPolley/tree_counting/10cm_Resamples/2022_UofC/StonyWest_10cm_clip.tif'\n",
    "#img_path = r'F:/MtPolley/tree_counting/10cm_Resamples/2022_UofC/StonyFen_10cm.tif'\n",
    "#img_path = r'E:/MtPolley_Project/4_GIS/for_CNN/ortho/2023_treecounting/2019_ortho/2019_ort_clip_AI_wrkshp.tif'\n",
    "out_path = r'C:/Users/jlovitt/Pyworking/for_CNN_5/RGB_aerial/inference/'\n",
    "#img_path = r'F:/MtPolley/tree_counting/10cm_Resamples/2021_SumacSouthON_10cm/n9_10cm.tif'\n",
    "\n",
    "site = \"newV1_2019ort_\"\n",
    "rgba_out = r'C:/Users/jlovitt/Pyworking/for_CNN_5/RGB_aerial/inference/'\n",
    "\n",
    "NoData = -9999 #enter NoData value of the incoming img\n",
    "tile_size = 128 #enter desired tile size between 64 - 128, default 128\n",
    "batch_size = 100 #enter batch size, max 250, default 100\n",
    "\n",
    "minval = 0 #enter min val for normalization, default 0\n",
    "maxval = 255 #enter max val for normalization, default 255\n",
    "\n",
    "generate_heatmap = True #enter 'False' or 'True'\n",
    "heatmap_algo = \"cgc\" #enter 'gc' for Grad-CAM, 'cgc' for custom Grad-CAM, or 'gcpp' for Grad-CAM++\n",
    "target_layer1 = \"batch_normalization_23\" #\"conv2d_23\" #conv layer you want to view activations for\n",
    "target_layer2 = \"batch_normalization_13\" #\"batch_normalization_7\",\"batch_normalization_19\"]\n",
    "           \n",
    "normalize_heatmap = \"local\" #enter 'none', 'local', or 'global'\n",
    "generate_rgba = False\n",
    "\n",
    "k1=3\n",
    "k2=7\n",
    "k3=15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26520d82",
   "metadata": {},
   "source": [
    "# Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c22945f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n",
      "Tensorflow ver. 2.8.0\n",
      "Device found : [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<details>\n",
       "<summary>Click to view session information</summary>\n",
       "<pre>\n",
       "-----\n",
       "PIL                 9.0.1\n",
       "cv2                 4.0.1\n",
       "ipynb               NA\n",
       "keras               2.8.0\n",
       "matplotlib          3.5.1\n",
       "numpy               1.21.5\n",
       "session_info        1.0.0\n",
       "tensorflow          2.8.0\n",
       "tifffile            2021.7.2\n",
       "-----\n",
       "</pre>\n",
       "<details>\n",
       "<summary>Click to view modules imported as dependencies</summary>\n",
       "<pre>\n",
       "aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42    NA\n",
       "absl                                        NA\n",
       "asttokens                                   NA\n",
       "astunparse                                  1.6.3\n",
       "backcall                                    0.2.0\n",
       "bottleneck                                  1.3.4\n",
       "brotli                                      NA\n",
       "certifi                                     2022.09.24\n",
       "cffi                                        1.15.0\n",
       "charset_normalizer                          2.0.12\n",
       "colorama                                    0.4.4\n",
       "cycler                                      0.10.0\n",
       "cython_runtime                              NA\n",
       "dateutil                                    2.8.2\n",
       "debugpy                                     1.5.1\n",
       "decorator                                   5.1.1\n",
       "defusedxml                                  0.7.1\n",
       "entrypoints                                 0.3\n",
       "executing                                   0.8.3\n",
       "flatbuffers                                 22.9.24\n",
       "gast                                        0.5.3\n",
       "google                                      NA\n",
       "h5py                                        3.7.0\n",
       "idna                                        3.3\n",
       "imagecodecs                                 2021.8.26\n",
       "importlib_metadata                          NA\n",
       "ipykernel                                   6.9.1\n",
       "ipython_genutils                            0.2.0\n",
       "jedi                                        0.18.1\n",
       "jupyter_server                              1.13.5\n",
       "keras_preprocessing                         1.1.2\n",
       "kiwisolver                                  1.3.2\n",
       "matplotlib_inline                           NA\n",
       "mkl                                         2.4.0\n",
       "mpl_toolkits                                NA\n",
       "nt                                          NA\n",
       "ntsecuritycon                               NA\n",
       "numexpr                                     2.8.1\n",
       "opt_einsum                                  v3.3.0\n",
       "packaging                                   21.3\n",
       "pandas                                      1.4.1\n",
       "parso                                       0.8.3\n",
       "pickleshare                                 0.7.5\n",
       "pkg_resources                               NA\n",
       "prompt_toolkit                              3.0.20\n",
       "pure_eval                                   0.2.2\n",
       "pydev_ipython                               NA\n",
       "pydevconsole                                NA\n",
       "pydevd                                      2.6.0\n",
       "pydevd_concurrency_analyser                 NA\n",
       "pydevd_file_utils                           NA\n",
       "pydevd_plugins                              NA\n",
       "pydevd_tracing                              NA\n",
       "pygments                                    2.11.2\n",
       "pyparsing                                   3.0.4\n",
       "pythoncom                                   NA\n",
       "pytz                                        2021.3\n",
       "pywintypes                                  NA\n",
       "requests                                    2.27.1\n",
       "scipy                                       1.7.3\n",
       "setuptools                                  61.2.0\n",
       "six                                         1.16.0\n",
       "socks                                       1.7.1\n",
       "stack_data                                  0.2.0\n",
       "tensorboard                                 2.8.0\n",
       "termcolor                                   NA\n",
       "tornado                                     6.1\n",
       "traitlets                                   5.1.1\n",
       "typing_extensions                           NA\n",
       "urllib3                                     1.26.9\n",
       "wcwidth                                     0.2.5\n",
       "win32api                                    NA\n",
       "win32com                                    NA\n",
       "win32security                               NA\n",
       "wrapt                                       1.14.1\n",
       "zipp                                        NA\n",
       "zmq                                         22.3.0\n",
       "</pre>\n",
       "</details> <!-- seems like this ends pre, so might as well be explicit -->\n",
       "<pre>\n",
       "-----\n",
       "IPython             8.2.0\n",
       "jupyter_client      7.1.2\n",
       "jupyter_core        4.9.2\n",
       "jupyterlab          3.3.2\n",
       "notebook            6.4.12\n",
       "-----\n",
       "Python 3.8.0 (default, Nov  6 2019, 16:00:02) [MSC v.1916 64 bit (AMD64)]\n",
       "Windows-10-10.0.19041-SP0\n",
       "-----\n",
       "Session information updated at 2023-09-18 11:29\n",
       "</pre>\n",
       "</details>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, sys, PIL,time,ipynb.fs, session_info,cv2\n",
    "import numpy as np\n",
    "import tifffile as tiff\n",
    "from PIL import Image\n",
    "Image.MAX_IMAGE_PIXELS = 5000000000\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.pyplot import imshow,figure\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "#from keras import models,layers\n",
    "#from tensorflow.keras.layers import Input, Conv2D,Conv1D, UpSampling2D,GlobalMaxPool2D,GlobalAveragePooling2D, concatenate,Dense, Flatten, Dropout,BatchNormalization, MaxPooling2D\n",
    "#from tensorflow.keras.models import Model, Sequential, load_model\n",
    "#from tensorflow.keras.optimizers import Adam\n",
    "print(tf.__version__)\n",
    "print(f\"Tensorflow ver. {tf.__version__}\")\n",
    "physical_device = tf.config.experimental.list_physical_devices('CPU')\n",
    "print(f'Device found : {physical_device}')\n",
    "#tf.config.experimental.get_memory_growth(physical_device[0])\n",
    "K.clear_session()\n",
    "\n",
    "#from ipynb.fs.full.TreeCRowNNv2_Functions_2 import *\n",
    "session_info.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251b6e11",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8f986bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padding : 0\n"
     ]
    }
   ],
   "source": [
    "padding = int((128-tile_size)/2)\n",
    "print(f\"padding : {padding}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd27f601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 255\n",
      "47 59951 39 36391\n",
      "47 59951 39 36391\n",
      "0 255 (36430, 59998, 3)\n"
     ]
    }
   ],
   "source": [
    "image = tiff.imread(img_path)\n",
    "image[image==NoData] = 0 #np.nan\n",
    "img = image[:,:,:3]\n",
    "print(img.min(),img.max())\n",
    "\n",
    "for i in range(0,2):\n",
    "    crop_image(img[:,:,i],tile_size)\n",
    "\n",
    "print(img.min(),img.max(),img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fdf1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1fa5d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y,x,chan = img.shape\n",
    "big_x = round(int(x/tile_size),0)\n",
    "cropx = (big_x*tile_size)\n",
    "big_y = round(int(y/tile_size),0)\n",
    "cropy = (big_y*tile_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81079583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284, 468) (36430, 59998)\n"
     ]
    }
   ],
   "source": [
    "blank_img = np.zeros([big_y,big_x],dtype=int)\n",
    "blank_img2 = np.zeros([y,x],dtype=np.float32)\n",
    "print(blank_img.shape,blank_img2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c073b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36430, 59998, 3)\n"
     ]
    }
   ],
   "source": [
    "if heatmap_algo == \"cgc\":\n",
    "    blank = np.zeros([y,x],dtype=np.float32)\n",
    "    blank_img3 = np.dstack([blank,blank,blank])\n",
    "\n",
    "    print(blank_img3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca18453",
   "metadata": {},
   "source": [
    "## Load Model and Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3084e8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_name='TreeCRowNNv2_V1_newdataWbblim_x1'\n",
    "def tc_model(lr,spe,u,u2,u3,k1,k2,k3):\n",
    "    import time\n",
    "    import tensorflow as tf\n",
    "    from tensorflow import keras\n",
    "    from keras import backend as K\n",
    "    from keras import models,layers\n",
    "    from tensorflow.keras.layers import Input, Conv2D,Conv1D, UpSampling2D,GlobalMaxPool2D,GlobalAveragePooling2D, concatenate,Dense, Flatten, Dropout,BatchNormalization, MaxPooling2D\n",
    "    from tensorflow.keras.models import Model, Sequential, load_model\n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "    \n",
    "    in1 = Input(shape=(128,128,3))\n",
    "    \n",
    "    conv1 = Conv2D(u,(k1,k1),activation='relu', padding='same')(in1)\n",
    "    #conv1.trainable = False\n",
    "    BN1 = BatchNormalization()(conv1)\n",
    "    #BN1.trainable = False\n",
    "    conv2 = Conv2D(u,(k1,k1),activation='relu', padding='same')(BN1)\n",
    "    #conv2.trainable = False\n",
    "    BN2 = BatchNormalization()(conv2)\n",
    "    #BN2.trainable = False\n",
    " \n",
    "    small1 = Conv2D(u,(k1,k1), activation='relu', padding='same')(BN2)\n",
    "    #small1.trainable = False\n",
    "    BN3 = BatchNormalization()(small1)\n",
    "    #BN3.trainable = False\n",
    "    small2 = Conv2D(u,(k1,k1), activation='relu', padding='same')(BN3)\n",
    "    #small2.trainable = False\n",
    "    BN4 = BatchNormalization()(small2)\n",
    "    #BN4.trainable = False\n",
    "    small3 = MaxPooling2D((2,2))(BN4)\n",
    "    #small3.trainable = False\n",
    "    small4 = Dropout(0.2)(small3)\n",
    "    \n",
    "    small5 = Conv2D(u,(k1,k1), activation='relu',padding='same')(small4)\n",
    "    #small5.trainable = False\n",
    "    BN5 = BatchNormalization()(small5)\n",
    "    #BN5.trainable = False\n",
    "    small6 = Conv2D(u,(k1,k1), activation='relu',padding='same')(BN5)\n",
    "    #small6.trainable = False\n",
    "    BN6 = BatchNormalization()(small6)\n",
    "    #BN6.trainable = False\n",
    "    small7 = Dropout(0.2)(BN6)\n",
    "    \n",
    "    small8 = Conv2D(u,(k1,k1), activation='relu',padding='same')(small7)\n",
    "    #small8.trainable = False\n",
    "    BN7 = BatchNormalization()(small8)\n",
    "    #BN7.trainable = False\n",
    "    small9 = Conv2D(u,(k1,k1), activation='relu',padding='same')(BN7)\n",
    "    #small9.trainable = False\n",
    "    BN8 = BatchNormalization()(small9)\n",
    "    #BN8.trainable = False\n",
    "    small10 = MaxPooling2D((2,2))(BN8)\n",
    "    #small10.trainable = False\n",
    "    small11 = Dropout(0.2)(small10)\n",
    "\n",
    "    med1 = Conv2D(u,(k2,k2), activation='relu', padding='same')(BN2)\n",
    "    #med1.trainable = False\n",
    "    BN9 = BatchNormalization()(med1)\n",
    "    #BN9.trainable = False\n",
    "    med2 = Conv2D(u,(k2,k2), activation='relu', padding='same')(BN9)\n",
    "    #med2.trainable = False\n",
    "    BN10 = BatchNormalization()(med2)\n",
    "    #BN10.trainable = False\n",
    "    med3 = MaxPooling2D((2,2))(BN10)\n",
    "    #med3.trainable = False\n",
    "    med4 = Dropout(0.2)(med3)\n",
    "    \n",
    "    med5 = Conv2D(u,(k2,k2), activation='relu',padding='same')(med4)\n",
    "    #med5.trainable = False\n",
    "    BN11 = BatchNormalization()(med5)\n",
    "    #BN11.trainable = False\n",
    "    med6 = Conv2D(u,(k2,k2), activation='relu',padding='same')(BN11)\n",
    "    #med6.trainable = False\n",
    "    BN12 = BatchNormalization()(med6)\n",
    "    #BN12.trainable = False\n",
    "    med7 = Dropout(0.2)(BN12)\n",
    "    \n",
    "    med8 = Conv2D(u,(k2,k2), activation='relu',padding='same')(med7)\n",
    "    #med8.trainable = False\n",
    "    BN13 = BatchNormalization()(med8)\n",
    "    #BN13.trainable = False\n",
    "    med9 = Conv2D(u,(k2,k2), activation='relu',padding='same')(BN13)\n",
    "    #med9.trainable = False\n",
    "    BN14 = BatchNormalization()(med9)\n",
    "    #BN14.trainable = False\n",
    "    med10 = MaxPooling2D((2,2))(BN14)\n",
    "    #med10.trainable = False\n",
    "    med11 = Dropout(0.2)(med10)\n",
    "\n",
    "    big1 = Conv2D(u,(k3,k3), activation='relu', padding='same')(BN2)\n",
    "    #big1.trainable = False\n",
    "    BN15 = BatchNormalization()(big1)\n",
    "    #BN15.trainable = False\n",
    "    big2 = Conv2D(u,(k3,k3), activation='relu', padding='same')(BN15)\n",
    "    #big2.trainable = False\n",
    "    BN16 = BatchNormalization()(big2)\n",
    "    #BN16.trainable = False\n",
    "    big3 = MaxPooling2D((2,2))(BN16)\n",
    "    #big3.trainable = False\n",
    "    big4 = Dropout(0.2)(big3)\n",
    "    \n",
    "    big5 = Conv2D(u,(k3,k3), activation='relu',padding='same')(big4)\n",
    "    #big5.trainable = False\n",
    "    BN17 = BatchNormalization()(big5)\n",
    "    #BN17.trainable = False\n",
    "    big6 = Conv2D(u,(k3,k3), activation='relu',padding='same')(BN17)\n",
    "    #big6.trainable = False\n",
    "    BN18 = BatchNormalization()(big6)\n",
    "    #BN18.trainable = False\n",
    "    big7 = Dropout(0.2)(BN18)\n",
    "    \n",
    "    big8 = Conv2D(u,(k3,k3), activation='relu',padding='same')(big7)\n",
    "    #big8.trainable = False\n",
    "    BN19 = BatchNormalization()(big8)\n",
    "    #BN19.trainable = False\n",
    "    big9 = Conv2D(u,(k3,k3), activation='relu',padding='same')(BN19)\n",
    "    #big9.trainable = False\n",
    "    BN20 = BatchNormalization()(big9)\n",
    "    #BN20.trainable = False\n",
    "    big10 = MaxPooling2D((2,2))(BN20)\n",
    "    #big10.trainable = False\n",
    "    big11 = Dropout(0.2)(big10)\n",
    "\n",
    "    concat1 = tf.keras.layers.Concatenate()([small11,med11,big11])\n",
    "\n",
    "    FC1 = Conv2D(u2,(1,1), activation='relu',padding='valid')(concat1)\n",
    "    BN21 = BatchNormalization()(FC1)\n",
    "    FC2 = Conv2D(u,(5,5), activation='relu',padding='valid')(BN21)\n",
    "    BN22 = BatchNormalization()(FC2)\n",
    "    FC3 = Conv2D(u,(5,5), activation='relu',padding='valid')(BN22)\n",
    "    BN23 = BatchNormalization()(FC3)\n",
    "    FC4 = Conv2D(u,(5,5), activation='relu',padding='valid')(BN23)\n",
    "    BN24 = BatchNormalization()(FC4)\n",
    "\n",
    "    \n",
    "    flat = Flatten()(BN24)\n",
    "\n",
    "    dense1 = keras.layers.Dense(u3, activation='relu')(flat)\n",
    "    BN25 = BatchNormalization()(dense1)\n",
    "    dense2 = keras.layers.Dense(u3, activation='relu')(BN25)\n",
    "    BN26 = BatchNormalization()(dense2)\n",
    "    dense3 = keras.layers.Dense(u3, activation='relu')(BN26)\n",
    "    BN27 = BatchNormalization()(dense3)\n",
    "    dense4 = keras.layers.Dense(u3, activation='relu')(BN27)\n",
    "    BN28 = BatchNormalization()(dense4)\n",
    "    dense5 = keras.layers.Dense(u3, activation='relu')(BN28)\n",
    "    BN29 = BatchNormalization()(dense5)\n",
    "    out1 = keras.layers.Dense(1, activation='linear')(BN29)\n",
    "\n",
    "    model = Model(inputs=[in1], outputs=[out1])\n",
    "\n",
    "    model.compile(loss=\"MeanAbsoluteError\", \n",
    "              optimizer =keras.optimizers.Adam(learning_rate=lr),\n",
    "              metrics=[tf.keras.metrics.MeanAbsoluteError(),tf.keras.metrics.MeanSquaredError()])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c61f403",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load best model and evaluate\n",
    "#lr,spe,u,u2,u3 = 0.001,160,16,16,16\n",
    "#lr,spe,u,u2,u3 = 0.001,160,8,16,12\n",
    "lr,spe,u,u2,u3,k1,k2,k3 = 0.001,160,16,12,12,3,7,15\n",
    "#path_to_weights = r\"C:/Users/jlovitt/Pyworking/for_CNN_5/RGB_aerial/log/logsGRSimple_xtra0_+dense/GRSimple_xtra0_+dense-2.11927mae-0r-[160, 0.001, 16, 16, 16]p-14297.24sec/Weights-2.11927_03142023_232824.h5\"\n",
    "#path_to_weights = r'C:/Users/jlovitt/Pyworking/padding/log/logsTreeCRowNNv2_wPaddingCombo_newdatasetV3c/TreeCRowNNv2_wPaddingCombo_newdatasetV3c-1.76054mae-16r-[160, 0.001, 12, 8, 8]p-6039.90sec/Weights-1.76054_08282023_054930.h5'\n",
    "#path_to_weights = r'C:/Users/jlovitt/Pyworking/TreeCRowNN_Transfer/ALL/log/logsTreeCRowNNv2_V3c_newdataWbblim_x1/TreeCRowNNv2_V3c_newdataWbblim_x1-2.77685mae-13r-[160, 0.001, 8, 16, 12]p-4951.83sec/Weights-2.77685_09072023_021159.h5'\n",
    "path_to_weights = r'C:/Users/jlovitt/Pyworking/TreeCRowNN_Transfer/ALL/log/logsTreeCRowNNv2_V1_newdataWbblim_x1/TreeCRowNNv2_V1_newdataWbblim_x1-2.67247mae-10r-[160, 0.001, 16, 12, 12]p-7053.12sec/Weights-2.67247_09142023_043256.h5'\n",
    "\n",
    "#path_to_weights = r\"C:/Users/jlovitt/Pyworking/padding/log/logsTreeCRowNNv2_wPaddingCombo_refinedV1/TreeCRowNNv2_wPaddingCombo_refinedV1-1.56268mae-32r-[160, 0.001, 8, 18, 8]p-17184.02sec/Weights-1.56268_07152023_231140.h5\"\n",
    "#path_to_weights = r\"C:/Users/jlovitt/Pyworking/padding/log/logsTreeCRowNNv2_wPaddingCombo_refinedV2/TreeCRowNNv2_wPaddingCombo_refinedV2-1.69208mae-0r-[160, 0.001, 16, 16, 16]p-8490.73sec/Weights-1.69208_07282023_222908.h5\"\n",
    "#path_to_weights = r\"C:/Users/jlovitt/Pyworking/padding/log/logsTreeCRowNNv2_wPaddingCombo_newdatasetV3/TreeCRowNNv2_wPaddingCombo_newdatasetV3-1.71451mae-31r-[160, 0.001, 12, 16, 16]p-8028.14sec/Weights-1.71451_08092023_103242.h5\"\n",
    "#path_to_weights = r\"C:/Users/jlovitt/Pyworking/padding/log/logsTreeCRowNNv2_wPaddingCombo_newdatasetV1b/TreeCRowNNv2_wPaddingCombo_newdatasetV1b-1.71872mae-0r-[160, 0.001, 8, 14, 16]p-7364.81sec/Weights-1.71872_08162023_170218.h5\"\n",
    "#path_to_weights = r\"C:/Users/jlovitt/Pyworking/padding/log/logsTreeCRowNNv2_wPaddingCombo_newdatasetV1c/TreeCRowNNv2_wPaddingCombo_newdatasetV1c-1.70292mae-35r-[160, 0.001, 14, 8, 16]p-4857.87sec/Weights-1.70292_08242023_022059.h5\"\n",
    "\n",
    "model=tc_model(lr,spe,u,u2,u3,k1,k2,k3)\n",
    "model.load_weights(path_to_weights)\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ca4b69",
   "metadata": {},
   "source": [
    "## Perform Batch Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90a785b",
   "metadata": {},
   "source": [
    "## Settings\n",
    "site = \"heatmap_test_\"\n",
    "rgba_out = r'C:/Users/jlovitt/Pyworking/for_CNN_5/RGB_aerial/inference/heat_test/'\n",
    "\n",
    "NoData = -9999 #enter NoData value of the incoming img\n",
    "tile_size = 128 #enter desired tile size between 64 - 128, default 128\n",
    "batch_size = 100 #enter batch size, max 250, default 100\n",
    "\n",
    "minval = 0 #enter min val for normalization, default 0\n",
    "maxval = 255 #enter max val for normalization, default 255\n",
    "\n",
    "generate_heatmap = True #enter 'False' or 'True'\n",
    "heatmap_algo = \"gc\" #enter 'gc' for Grad-CAM or 'gcpp' for Grad-CAM++\n",
    "target_layer = \"batch_normalization_23\" #\"conv2d_23\" #conv layer you want to view activations for\n",
    "normalize_heatmap = \"none\" #enter 'none', 'local', or 'global'\n",
    "generate_rgba = False\n",
    "\n",
    "k1=3\n",
    "k2=16\n",
    "k3=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0df8aa5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL BLOCKS :  132912\n",
      "BATCH SIZE :  100\n"
     ]
    }
   ],
   "source": [
    "#tree_counts2,T2 = create_image2(img,blank_img,tile_size,model,chan,padding,minval,maxval,batch_size)\n",
    "T2 = create_image2(img,\n",
    "                   blank_img,\n",
    "                   blank_img2,\n",
    "                   tile_size,\n",
    "                   model,\n",
    "                   minval,\n",
    "                   maxval,\n",
    "                   batch_size,\n",
    "                   #\"conv2d_23\",\n",
    "                   \"batch_normalization_23\",\n",
    "                   \"batch_normalization_13\",\n",
    "                   generate_heatmap,\n",
    "                   heatmap_algo,\n",
    "                   normalize_heatmap,\n",
    "                   generate_rgba,\n",
    "                   rgba_out)\n",
    "print((big_y*big_x),\" BLOCKS PROCESSED IN \",round(T2,3), ' SECONDS')\n",
    "print(\"TOTAL TIME PER BLOCK : \", (T2/(big_y*big_x)),\"sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee39bf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_trees = str(np.ndarray.sum(blank_img))\n",
    "m = tile_size/10\n",
    "area = round(((big_y*big_x)*(m*m)),2)\n",
    "print(\"TOTAL TREES PREDICTED WITH TILE SIZE \" +str(tile_size)+\" : \" + total_trees)  \n",
    "print(\"(COL, ROW)\",blank_img.shape)\n",
    "print(\"TOTAL AREA PROCESSED : \",area, \"m2 --> \",round(area/10000,2), \"ha\")\n",
    "print(\"TOTAL PROCESSING TIME : \",round(T2/60,1),\"MINUTES\")\n",
    "print(\"PREDICTED RANGE : \",blank_img.min(),\" to \",blank_img.max(), \" TREES\")\n",
    "\n",
    "#plt.subplot(1,2,1)\n",
    "#plt.set_title(\"INPUT\")\n",
    "#plt.imshow(img//255)\n",
    "#plt.subplot(1,2,2)\n",
    "#plt.set_title(\"PREDICTION\")\n",
    "plt.imshow(blank_img)\n",
    "#plt.tight_layout()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ec7852",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_trees = str(np.ndarray.sum(blank_img))\n",
    "plt.imshow(blank_img2)\n",
    "print(\"TOTAL TREES PREDICTED WITH TILE SIZE \" +str(tile_size)+\" : \" + total_trees)  \n",
    "print(blank_img.shape)\n",
    "blank_img.min(),blank_img.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dad8b43",
   "metadata": {},
   "source": [
    "## Write Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ec94a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write FSD map\n",
    "tiff.imwrite(str(os.path.join(out_path+site+\"_totaltrees_\"+total_trees+'.tif')),blank_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad871398",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_heatmap='global'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80c745a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write activation map if requested\n",
    "if generate_heatmap == True:\n",
    "    if normalize_heatmap == \"local\":\n",
    "        tiff.imwrite(str(os.path.join(out_path+site+\"ts\"+str(tile_size)+\"_heatmap_localNorm_\"+str(heatmap_algo)+'.tif')),blank_img2)\n",
    "    elif normalize_heatmap == \"global\":\n",
    "        n_heatmap = normalize_activations(blank_img3)\n",
    "        tiff.imwrite(str(os.path.join(out_path+site+\"ts\"+str(tile_size)+\"_heatmap_globalNorm_\"+str(heatmap_algo)+'.tif')),n_heatmap)\n",
    "    elif normalize_heatmap == \"none\":\n",
    "        tiff.imwrite(str(os.path.join(out_path+site+\"ts\"+str(tile_size)+\"heatmap_noNorm_\"+str(heatmap_algo)+'.tif')),blank_img2) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa28913a",
   "metadata": {},
   "source": [
    "## activation map test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b5688f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predict(patch):\n",
    "    import numpy as np\n",
    "    prediction = np.mean(patch)\n",
    "    prediction = np.rint(prediction)\n",
    "    if prediction < 0.0:\n",
    "        prediction = 0.0 \n",
    "    return prediction\n",
    "\n",
    "def create_image2(img,blank_img,blank_img2,tile_size,model,chan,padding,minval,maxval,batch_size,target_layer):\n",
    "    import numpy as np\n",
    "    import time\n",
    "    import tensorflow as tf\n",
    "    from tensorflow import keras\n",
    "    from keras import backend as K\n",
    "    from keras import models,layers\n",
    "    from tensorflow.keras.layers import Input, Conv2D,Conv1D, UpSampling2D,GlobalMaxPool2D,GlobalAveragePooling2D, concatenate,Dense, Flatten, Dropout,BatchNormalization, MaxPooling2D\n",
    "    from tensorflow.keras.models import Model, Sequential, load_model\n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "    \n",
    "    t1 = time.time()\n",
    "    predictions = []\n",
    "    activations = []\n",
    "        \n",
    "    y,x,z = img.shape\n",
    "    nblocks_row = int(y//tile_size)\n",
    "    nblocks_col = int(x//tile_size)\n",
    "    total_blocks = nblocks_row*nblocks_col\n",
    "    print(\"TOTAL BLOCKS : \",total_blocks)\n",
    "    print(\"BATCH SIZE : \",batch_size)\n",
    "        \n",
    "    row_list = range(0,nblocks_row)\n",
    "    col_list = range(0,nblocks_col)\n",
    "        \n",
    "    n = 0\n",
    "    dataset = []\n",
    "    coords = []\n",
    "    blocks = []\n",
    "        \n",
    "    for i in row_list:\n",
    "        for j in col_list:\n",
    "                \n",
    "            row_start = i\n",
    "            row_start = row_start*tile_size\n",
    "            row_end = row_start + tile_size\n",
    "            col_start = j\n",
    "            col_start = col_start*tile_size\n",
    "            col_end = col_start + tile_size\n",
    "            \n",
    "            block = np.array([row_start,row_end,col_start,col_end]).astype('int32')\n",
    "            blocks.append(block)\n",
    "        \n",
    "            patch = img[row_start:row_end,col_start:col_end]\n",
    "            patch = tf.cast(patch,tf.float32)/maxval\n",
    "            patch = tf.reshape(patch, shape=[1, tile_size, tile_size, chan])\n",
    "            patch = tf.keras.layers.ZeroPadding2D(padding=padding)(patch)\n",
    "            coords.append([i,j])\n",
    "            dataset.append(patch)\n",
    "            n+=1\n",
    "            if len(dataset)>=batch_size:\n",
    "                dataset2 = tf.data.Dataset.from_tensor_slices(dataset)\n",
    "                result = model.predict(dataset2)\n",
    "                for k in range (len(result)):\n",
    "                    predict = get_predict(result[k])\n",
    "                    blank_img[coords[k][0],coords[k][1]]=predict\n",
    "                    predictions.append(result[k])\n",
    "                coords=[]\n",
    "                dataset = []\n",
    "            if str(n)[-4:]=='0000':\n",
    "                t2 = time.time()-t1\n",
    "                print('{} pixels processed in {}, {}% done'.format(n,t2,str(\"%.2f\"%(n/total_blocks*100))))\n",
    "    print(\"FINAL PIXELS\")\n",
    "    dataset2 = tf.data.Dataset.from_tensor_slices(dataset)\n",
    "    result = model.predict(dataset2)\n",
    "    for k in range (len(result)):\n",
    "        predict = get_predict(result[k])\n",
    "        blank_img[coords[k][0],coords[k][1]]=predict\n",
    "        predictions.append(result[k])\n",
    "    \n",
    "    t3=time.time()     \n",
    "    total_time = t3-t1\n",
    "        \n",
    "    return predictions,blocks,total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f367b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_heatmap(img_array, model, last_conv, tile_size, padding, pred_index=None):\n",
    "    import numpy as np\n",
    "    import tensorflow as tf\n",
    "    from tensorflow import keras\n",
    "    import cv2\n",
    "    grad_model = keras.models.Model(model.inputs,[model.get_layer(last_conv).output,model.output])\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_output, preds = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(preds[0])\n",
    "        class_channel = preds[:,pred_index]\n",
    "        \n",
    "        grads = tape.gradient(class_channel, last_conv_output)\n",
    "        pooled_grads = tf.reduce_mean(grads,axis=(0,1,2))\n",
    "        \n",
    "        last_conv_output = last_conv_output[0]\n",
    "        heatmap = last_conv_output @ pooled_grads[...,tf.newaxis]\n",
    "        heatmap = tf.squeeze(heatmap)         \n",
    "        #heatmap = tf.maximum(heatmap,-1)/tf.math.reduce_max(heatmap)\n",
    "        #heatmap = heatmap/tf.math.reduce_max(heatmap)\n",
    "        #print(heatmap.numpy())\n",
    "        heatmap = cv2.resize(heatmap.numpy(),(tile_size+(2*padding),tile_size+(2*padding)))\n",
    "        #heatmap = (heatmap*255).astype(\"uint8\")\n",
    "        #print(heatmap)\n",
    "        \n",
    "        if padding != 0:\n",
    "            heatmap = heatmap[padding:-padding,padding:-padding]\n",
    "        return heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3682035",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_heatmap(in1, model, last_conv,tile_size,padding,pred_index=None):\n",
    "    import numpy as np\n",
    "    import tensorflow as tf\n",
    "    from tensorflow import keras\n",
    "    import cv2\n",
    "    \n",
    "    grad_model = keras.models.Model(model.inputs,[model.get_layer(last_conv).output,model.output])\n",
    "    \n",
    "    with tf.GradientTape(persistent=False) as tape:\n",
    "        last_conv_output, preds = grad_model(in1)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(preds[0])\n",
    "            \n",
    "        #generate activation heatmap\n",
    "        class_channel = preds[:,pred_index]\n",
    "        grads = tape.gradient(class_channel, last_conv_output)\n",
    "        pooled_grads = tf.reduce_mean(grads,axis=(0,1,2))\n",
    "            \n",
    "        last_conv_output = last_conv_output[0]\n",
    "        heatmap = last_conv_output @ pooled_grads[...,tf.newaxis]\n",
    "        heatmap = tf.squeeze(heatmap)\n",
    "            \n",
    "        heatmap = cv2.resize(heatmap.numpy(),(tile_size+(2*padding),tile_size+(2*padding)))\n",
    "        heatmap = heatmap[padding:-padding,padding:-padding]\n",
    "            \n",
    "        numer = heatmap-np.min(heatmap)\n",
    "        denom = (heatmap.max()-heatmap.min())+1e-8\n",
    "        heatmap = numer/denom\n",
    "        #heatmap = (heatmap*255).astype(\"uint8\") \n",
    "    \n",
    "    return heatmap\n",
    "                                 \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abf2b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predict(patch):\n",
    "    import numpy as np\n",
    "    prediction = np.mean(patch)\n",
    "    prediction = np.rint(prediction)\n",
    "    if prediction < 0.0:\n",
    "        prediction = 0.0 \n",
    "    return prediction\n",
    "\n",
    "def create_image2(img,blank_img,blank_img2,tile_size,model,chan,padding,minval,maxval,batch_size,target_layer):\n",
    "    import numpy as np\n",
    "    import time\n",
    "    import tensorflow as tf\n",
    "    from tensorflow import keras\n",
    "    from keras import backend as K\n",
    "    from keras import models,layers\n",
    "    from tensorflow.keras.layers import Input, Conv2D,Conv1D, UpSampling2D,GlobalMaxPool2D,GlobalAveragePooling2D, concatenate,Dense, Flatten, Dropout,BatchNormalization, MaxPooling2D\n",
    "    from tensorflow.keras.models import Model, Sequential, load_model\n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "    \n",
    "    t1 = time.time()\n",
    "    predictions = []\n",
    "    activations = []\n",
    "        \n",
    "    y,x,z = img.shape\n",
    "    nblocks_row = int(y//tile_size)\n",
    "    nblocks_col = int(x//tile_size)\n",
    "    total_blocks = nblocks_row*nblocks_col\n",
    "    print(\"TOTAL BLOCKS : \",total_blocks)\n",
    "    print(\"BATCH SIZE : \",batch_size)\n",
    "        \n",
    "    row_list = range(0,nblocks_row)\n",
    "    col_list = range(0,nblocks_col)\n",
    "        \n",
    "    n = 0\n",
    "    dataset = []\n",
    "    coords = []\n",
    "    blocks = []\n",
    "        \n",
    "    for i in row_list:\n",
    "        for j in col_list:\n",
    "                \n",
    "            row_start = i\n",
    "            row_start = row_start*tile_size\n",
    "            row_end = row_start + tile_size\n",
    "            col_start = j\n",
    "            col_start = col_start*tile_size\n",
    "            col_end = col_start + tile_size\n",
    "            \n",
    "            block = np.array([row_start,row_end,col_start,col_end]).astype('int32')\n",
    "            blocks.append(block)\n",
    "        \n",
    "            patch = img[row_start:row_end,col_start:col_end]\n",
    "            patch = tf.cast(patch,tf.float32)/maxval\n",
    "            patch = tf.reshape(patch, shape=[1, tile_size, tile_size, chan])\n",
    "            patch = tf.keras.layers.ZeroPadding2D(padding=padding)(patch)\n",
    "            \n",
    "            heatmap = get_heatmap(patch,model, target_layer,tile_size,padding)\n",
    "            blank_img2[block[0]:block[1],block[2]:block[3]]=heatmap\n",
    "            \n",
    "            coords.append([i,j])\n",
    "            dataset.append(patch)\n",
    "            n+=1\n",
    "            if len(dataset)>=batch_size:\n",
    "                dataset2 = tf.data.Dataset.from_tensor_slices(dataset)\n",
    "                result = model.predict(dataset2)\n",
    "                for k in range (len(result)):\n",
    "                    predict = get_predict(result[k])\n",
    "                    blank_img[coords[k][0],coords[k][1]]=predict\n",
    "                    predictions.append(result[k])\n",
    "                coords=[]\n",
    "                dataset = []\n",
    "            if str(n)[-4:]=='0000':\n",
    "                t2 = time.time()-t1\n",
    "                print('{} pixels processed in {}, {}% done'.format(n,t2,str(\"%.2f\"%(n/total_blocks*100))))\n",
    "    print(\"FINAL PIXELS\")\n",
    "    dataset2 = tf.data.Dataset.from_tensor_slices(dataset)\n",
    "    result = model.predict(dataset2)\n",
    "    for k in range (len(result)):\n",
    "        predict = get_predict(result[k])\n",
    "        blank_img[coords[k][0],coords[k][1]]=predict\n",
    "        predictions.append(result[k])\n",
    "    \n",
    "    t3=time.time()     \n",
    "    total_time = t3-t1\n",
    "        \n",
    "    return predictions,blocks,total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e30222",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_counts2,img_blocks,T2 = create_image2(img,blank_img,blank_img2,tile_size,model,chan,padding,minval,maxval,batch_size,\"batch_normalization_23\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cd4be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(blank_img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8e0e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "print((big_y*big_x),\" BLOCKS PROCESSED IN \",round(T2,3), ' SECONDS')\n",
    "print(\"TOTAL TIME PER BLOCK : \", (T2/(big_y*big_x)),\"sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74dd0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiff.imwrite(str(os.path.join(out_path+site+'_activations'+'.tif')),blank_img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad1d050",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "acb11e39",
   "metadata": {},
   "source": [
    "NN_name='TreeCRowNNv2_wPaddingCombo_newdatasetV1c'\n",
    "def tc_model(lr,spe,u,u2,u3):\n",
    "    import time\n",
    "    import tensorflow as tf\n",
    "    from tensorflow import keras\n",
    "    from keras import backend as K\n",
    "    from keras import models,layers\n",
    "    from tensorflow.keras.layers import Input, Conv2D,Conv1D, UpSampling2D,GlobalMaxPool2D,GlobalAveragePooling2D, concatenate,Dense, Flatten, Dropout,BatchNormalization, MaxPooling2D\n",
    "    from tensorflow.keras.models import Model, Sequential, load_model\n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "    \n",
    "    in1 = Input(shape=(128,128,3))\n",
    "    \n",
    "    conv1 = Conv2D(u,(3,3),activation='relu', padding='same')(in1)\n",
    "    BN1 = BatchNormalization()(conv1)\n",
    "    conv2 = Conv2D(u,(3,3),activation='relu', padding='same')(BN1)\n",
    "    BN2 = BatchNormalization()(conv2)\n",
    " \n",
    "    small1 = Conv2D(u,(3, 3), activation='relu', padding='same')(BN2)\n",
    "    BN3 = BatchNormalization()(small1)\n",
    "    small2 = Conv2D(u,(3, 3), activation='relu', padding='same')(BN3)\n",
    "    BN4 = BatchNormalization()(small2)\n",
    "    small3 = MaxPooling2D((2,2))(BN4)\n",
    "    small4 = Dropout(0.2)(small3)\n",
    "    \n",
    "    small5 = Conv2D(u,(3,3), activation='relu',padding='same')(small4)\n",
    "    BN5 = BatchNormalization()(small5)\n",
    "    small6 = Conv2D(u,(3,3), activation='relu',padding='same')(BN5)\n",
    "    BN6 = BatchNormalization()(small6)\n",
    "    small7 = Dropout(0.2)(BN6)\n",
    "    \n",
    "    small8 = Conv2D(u,(3,3), activation='relu',padding='same')(small7)\n",
    "    BN7 = BatchNormalization()(small8)\n",
    "    small9 = Conv2D(u,(3,3), activation='relu',padding='same')(BN7)\n",
    "    BN8 = BatchNormalization()(small9)\n",
    "    small10 = MaxPooling2D((2,2))(BN8)\n",
    "    small11 = Dropout(0.2)(small10)\n",
    "\n",
    "    med1 = Conv2D(u,(7, 7), activation='relu', padding='same')(BN2)\n",
    "    BN9 = BatchNormalization()(med1)\n",
    "    med2 = Conv2D(u,(7, 7), activation='relu', padding='same')(BN9)\n",
    "    BN10 = BatchNormalization()(med2)\n",
    "    med3 = MaxPooling2D((2,2))(BN10)\n",
    "    med4 = Dropout(0.2)(med3)\n",
    "    \n",
    "    med5 = Conv2D(u,(7, 7), activation='relu',padding='same')(med4)\n",
    "    BN11 = BatchNormalization()(med5)\n",
    "    med6 = Conv2D(u,(7, 7), activation='relu',padding='same')(BN11)\n",
    "    BN12 = BatchNormalization()(med6)\n",
    "    med7 = Dropout(0.2)(BN12)\n",
    "    \n",
    "    med8 = Conv2D(u,(7, 7), activation='relu',padding='same')(med7)\n",
    "    BN13 = BatchNormalization()(med8)\n",
    "    med9 = Conv2D(u,(7, 7), activation='relu',padding='same')(BN13)\n",
    "    BN14 = BatchNormalization()(med9)\n",
    "    med10 = MaxPooling2D((2,2))(BN14)\n",
    "    med11 = Dropout(0.2)(med10)\n",
    "\n",
    "    big1 = Conv2D(u,(15, 15), activation='relu', padding='same')(BN2)\n",
    "    BN15 = BatchNormalization()(big1)\n",
    "    big2 = Conv2D(u,(15, 15), activation='relu', padding='same')(BN15)\n",
    "    BN16 = BatchNormalization()(big2)\n",
    "    big3 = MaxPooling2D((2,2))(BN16)\n",
    "    big4 = Dropout(0.2)(big3)\n",
    "    \n",
    "    big5 = Conv2D(u,(15, 15), activation='relu',padding='same')(big4)\n",
    "    BN17 = BatchNormalization()(big5)\n",
    "    big6 = Conv2D(u,(15, 15), activation='relu',padding='same')(BN17)\n",
    "    BN18 = BatchNormalization()(big6)\n",
    "    big7 = Dropout(0.2)(BN18)\n",
    "    \n",
    "    big8 = Conv2D(u,(15, 15), activation='relu',padding='same')(big7)\n",
    "    BN19 = BatchNormalization()(big8)\n",
    "    big9 = Conv2D(u,(15, 15), activation='relu',padding='same')(BN19)\n",
    "    BN20 = BatchNormalization()(big9)\n",
    "    big10 = MaxPooling2D((2,2))(BN20)\n",
    "    big11 = Dropout(0.2)(big10)\n",
    "\n",
    "    concat1 = tf.keras.layers.Concatenate()([small11,med11,big11])\n",
    "\n",
    "    FC1 = Conv2D(u2,(1,1), activation='relu',padding='valid')(concat1)\n",
    "    BN21 = BatchNormalization()(FC1)\n",
    "    FC2 = Conv2D(u,(5,5), activation='relu',padding='valid')(BN21)\n",
    "    BN22 = BatchNormalization()(FC2)\n",
    "    FC3 = Conv2D(u,(5,5), activation='relu',padding='valid')(BN22)\n",
    "    BN23 = BatchNormalization()(FC3)\n",
    "    FC4 = Conv2D(u,(5,5), activation='relu',padding='valid')(BN23)\n",
    "    BN24 = BatchNormalization()(FC4)\n",
    "    \n",
    "    flat = Flatten()(BN24)\n",
    "\n",
    "    dense1 = keras.layers.Dense(u3, activation='relu')(flat)\n",
    "    BN25 = BatchNormalization()(dense1)\n",
    "    dense2 = keras.layers.Dense(u3, activation='relu')(BN25)\n",
    "    BN26 = BatchNormalization()(dense2)\n",
    "    dense3 = keras.layers.Dense(u3, activation='relu')(BN26)\n",
    "    BN27 = BatchNormalization()(dense3)\n",
    "    dense4 = keras.layers.Dense(u3, activation='relu')(BN27)\n",
    "    BN28 = BatchNormalization()(dense4)\n",
    "    dense5 = keras.layers.Dense(u3, activation='relu')(BN28)\n",
    "    BN29 = BatchNormalization()(dense5)\n",
    "    out1 = keras.layers.Dense(1, activation='linear')(BN29)\n",
    "\n",
    "    model = Model(inputs=[in1], outputs=[out1])\n",
    "\n",
    "    model.compile(loss=\"MeanAbsoluteError\", \n",
    "              optimizer =keras.optimizers.Adam(learning_rate=lr),\n",
    "              metrics=[tf.keras.metrics.MeanAbsoluteError(),tf.keras.metrics.MeanSquaredError()])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ebdac6",
   "metadata": {},
   "source": [
    "NN_name='TreeCRowNNv2_wPaddingCombo_newdatasetV1'\n",
    "def tc_model(lr,spe,u,u2,u3):\n",
    "    import time\n",
    "    import tensorflow as tf\n",
    "    from tensorflow import keras\n",
    "    from keras import backend as K\n",
    "    from keras import models,layers\n",
    "    from tensorflow.keras.layers import Input, Conv2D,Conv1D, UpSampling2D,GlobalMaxPool2D,GlobalAveragePooling2D, concatenate,Dense, Flatten, Dropout,BatchNormalization, MaxPooling2D\n",
    "    from tensorflow.keras.models import Model, Sequential, load_model\n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "    \n",
    "    in1 = Input(shape=(128,128,3))\n",
    "    \n",
    "    conv1 = Conv2D(u,(3,3),activation='relu', padding='same')(in1)\n",
    "    BN1 = BatchNormalization()(conv1)\n",
    "    conv2 = Conv2D(u,(3,3),activation='relu', padding='same')(BN1)\n",
    "    BN2 = BatchNormalization()(conv2)\n",
    " \n",
    "    small1 = Conv2D(u,(3, 3), activation='relu', padding='same')(BN2)\n",
    "    BN3 = BatchNormalization()(small1)\n",
    "    small2 = Conv2D(u,(3, 3), activation='relu', padding='same')(BN3)\n",
    "    BN4 = BatchNormalization()(small2)\n",
    "    small3 = MaxPooling2D((2,2))(BN4)\n",
    "    small4 = Dropout(0.2)(small3)\n",
    "    \n",
    "    small5 = Conv2D(u,(3,3), activation='relu',padding='same')(small4)\n",
    "    BN5 = BatchNormalization()(small5)\n",
    "    small6 = Conv2D(u,(3,3), activation='relu',padding='same')(BN5)\n",
    "    BN6 = BatchNormalization()(small6)\n",
    "    small7 = Dropout(0.2)(BN6)\n",
    "    \n",
    "    small8 = Conv2D(u,(3,3), activation='relu',padding='same')(small7)\n",
    "    BN7 = BatchNormalization()(small8)\n",
    "    small9 = Conv2D(u,(3,3), activation='relu',padding='same')(BN7)\n",
    "    BN8 = BatchNormalization()(small9)\n",
    "    small10 = MaxPooling2D((2,2))(BN8)\n",
    "    small11 = Dropout(0.2)(small10)\n",
    "\n",
    "    med1 = Conv2D(u,(7, 7), activation='relu', padding='same')(BN2)\n",
    "    BN9 = BatchNormalization()(med1)\n",
    "    med2 = Conv2D(u,(7, 7), activation='relu', padding='same')(BN9)\n",
    "    BN10 = BatchNormalization()(med2)\n",
    "    med3 = MaxPooling2D((2,2))(BN10)\n",
    "    med4 = Dropout(0.2)(med3)\n",
    "    \n",
    "    med5 = Conv2D(u,(7, 7), activation='relu',padding='same')(med4)\n",
    "    BN11 = BatchNormalization()(med5)\n",
    "    med6 = Conv2D(u,(7, 7), activation='relu',padding='same')(BN11)\n",
    "    BN12 = BatchNormalization()(med6)\n",
    "    med7 = Dropout(0.2)(BN12)\n",
    "    \n",
    "    med8 = Conv2D(u,(7, 7), activation='relu',padding='same')(med7)\n",
    "    BN13 = BatchNormalization()(med8)\n",
    "    med9 = Conv2D(u,(7, 7), activation='relu',padding='same')(BN13)\n",
    "    BN14 = BatchNormalization()(med9)\n",
    "    med10 = MaxPooling2D((2,2))(BN14)\n",
    "    med11 = Dropout(0.2)(med10)\n",
    "\n",
    "    big1 = Conv2D(u,(15, 15), activation='relu', padding='same')(BN2)\n",
    "    BN15 = BatchNormalization()(big1)\n",
    "    big2 = Conv2D(u,(15, 15), activation='relu', padding='same')(BN15)\n",
    "    BN16 = BatchNormalization()(big2)\n",
    "    big3 = MaxPooling2D((2,2))(BN16)\n",
    "    big4 = Dropout(0.2)(big3)\n",
    "    \n",
    "    big5 = Conv2D(u,(15, 15), activation='relu',padding='same')(big4)\n",
    "    BN17 = BatchNormalization()(big5)\n",
    "    big6 = Conv2D(u,(15, 15), activation='relu',padding='same')(BN17)\n",
    "    BN18 = BatchNormalization()(big6)\n",
    "    big7 = Dropout(0.2)(BN18)\n",
    "    \n",
    "    big8 = Conv2D(u,(15, 15), activation='relu',padding='same')(big7)\n",
    "    BN19 = BatchNormalization()(big8)\n",
    "    big9 = Conv2D(u,(15, 15), activation='relu',padding='same')(BN19)\n",
    "    BN20 = BatchNormalization()(big9)\n",
    "    big10 = MaxPooling2D((2,2))(BN20)\n",
    "    big11 = Dropout(0.2)(big10)\n",
    "\n",
    "    concat1 = tf.keras.layers.Concatenate()([small11,med11,big11])\n",
    "\n",
    "    FC1 = Conv2D(u2,(1,1), activation='relu',padding='valid')(concat1)\n",
    "    BN21 = BatchNormalization()(FC1)\n",
    "    FC2 = Conv2D(u,(5,5), activation='relu',padding='valid')(BN21)\n",
    "    BN22 = BatchNormalization()(FC2)\n",
    "    FC3 = Conv2D(u,(5,5), activation='relu',padding='valid')(BN22)\n",
    "    BN23 = BatchNormalization()(FC3)\n",
    "    FC4 = Conv2D(u,(5,5), activation='relu',padding='valid')(BN23)\n",
    "    BN24 = BatchNormalization()(FC4)\n",
    "\n",
    "    \n",
    "    flat = Flatten()(BN24)\n",
    "\n",
    "    dense1 = keras.layers.Dense(u3, activation='relu')(flat)\n",
    "    BN25 = BatchNormalization()(dense1)\n",
    "    dense2 = keras.layers.Dense(u3, activation='relu')(BN25)\n",
    "    BN26 = BatchNormalization()(dense2)\n",
    "    dense3 = keras.layers.Dense(u3, activation='relu')(BN26)\n",
    "    BN27 = BatchNormalization()(dense3)\n",
    "    dense4 = keras.layers.Dense(u3, activation='relu')(BN27)\n",
    "    BN28 = BatchNormalization()(dense4)\n",
    "    dense5 = keras.layers.Dense(u3, activation='relu')(BN28)\n",
    "    BN29 = BatchNormalization()(dense5)\n",
    "    out1 = keras.layers.Dense(1, activation='linear')(BN29)\n",
    "\n",
    "    model = Model(inputs=[in1], outputs=[out1])\n",
    "\n",
    "    model.compile(loss=\"MeanAbsoluteError\", \n",
    "              optimizer =keras.optimizers.Adam(learning_rate=lr),\n",
    "              metrics=[tf.keras.metrics.MeanAbsoluteError(),tf.keras.metrics.MeanSquaredError()])\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175b7161",
   "metadata": {},
   "source": [
    "NN_name='TreeCRowNNv2_wPaddingCombo_newdatasetV3c'\n",
    "def tc_model(lr,spe,u,u2,u3):\n",
    "    import time\n",
    "    import tensorflow as tf\n",
    "    from tensorflow import keras\n",
    "    from keras import backend as K\n",
    "    from keras import models,layers\n",
    "    from tensorflow.keras.layers import Input, Conv2D,Conv1D, UpSampling2D,GlobalMaxPool2D,GlobalAveragePooling2D, concatenate,Dense, Flatten, Dropout,BatchNormalization, MaxPooling2D\n",
    "    from tensorflow.keras.models import Model, Sequential, load_model\n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "    \n",
    "    in1 = Input(shape=(128,128,3))\n",
    "    \n",
    "    conv1 = Conv2D(u,(3,3),activation='relu', padding='same')(in1)\n",
    "    BN1 = BatchNormalization()(conv1)\n",
    "    conv2 = Conv2D(u,(3,3),activation='relu', padding='same')(BN1)\n",
    "    BN2 = BatchNormalization()(conv2)\n",
    " \n",
    "    small1 = Conv2D(u,(3, 3), activation='relu', padding='same')(BN2)\n",
    "    BN3 = BatchNormalization()(small1)\n",
    "    small2 = Conv2D(u,(3, 3), activation='relu', padding='same')(BN3)\n",
    "    BN4 = BatchNormalization()(small2)\n",
    "    small3 = MaxPooling2D((2,2))(BN4)\n",
    "    small4 = Dropout(0.2)(small3)\n",
    "    \n",
    "    small5 = Conv2D(u,(3,3), activation='relu',padding='same')(small4)\n",
    "    BN5 = BatchNormalization()(small5)\n",
    "    small6 = Conv2D(u,(3,3), activation='relu',padding='same')(BN5)\n",
    "    BN6 = BatchNormalization()(small6)\n",
    "    small7 = Dropout(0.2)(BN6)\n",
    "    \n",
    "    small8 = Conv2D(u,(3,3), activation='relu',padding='same')(small7)\n",
    "    BN7 = BatchNormalization()(small8)\n",
    "    small9 = Conv2D(u,(3,3), activation='relu',padding='same')(BN7)\n",
    "    BN8 = BatchNormalization()(small9)\n",
    "    small10 = MaxPooling2D((2,2))(BN8)\n",
    "    small11 = Dropout(0.2)(small10)\n",
    "\n",
    "    med1 = Conv2D(u,(16, 16), activation='relu', padding='same')(BN2)\n",
    "    BN9 = BatchNormalization()(med1)\n",
    "    med2 = Conv2D(u,(16, 16), activation='relu', padding='same')(BN9)\n",
    "    BN10 = BatchNormalization()(med2)\n",
    "    med3 = MaxPooling2D((2,2))(BN10)\n",
    "    med4 = Dropout(0.2)(med3)\n",
    "    \n",
    "    med5 = Conv2D(u,(16, 16), activation='relu',padding='same')(med4)\n",
    "    BN11 = BatchNormalization()(med5)\n",
    "    med6 = Conv2D(u,(16, 16), activation='relu',padding='same')(BN11)\n",
    "    BN12 = BatchNormalization()(med6)\n",
    "    med7 = Dropout(0.2)(BN12)\n",
    "    \n",
    "    med8 = Conv2D(u,(16, 16), activation='relu',padding='same')(med7)\n",
    "    BN13 = BatchNormalization()(med8)\n",
    "    med9 = Conv2D(u,(16, 16), activation='relu',padding='same')(BN13)\n",
    "    BN14 = BatchNormalization()(med9)\n",
    "    med10 = MaxPooling2D((2,2))(BN14)\n",
    "    med11 = Dropout(0.2)(med10)\n",
    "\n",
    "    big1 = Conv2D(u,(64, 64), activation='relu', padding='same')(BN2)\n",
    "    BN15 = BatchNormalization()(big1)\n",
    "    big2 = Conv2D(u,(64, 64), activation='relu', padding='same')(BN15)\n",
    "    BN16 = BatchNormalization()(big2)\n",
    "    big3 = MaxPooling2D((2,2))(BN16)\n",
    "    big4 = Dropout(0.2)(big3)\n",
    "    \n",
    "    big5 = Conv2D(u,(64, 64), activation='relu',padding='same')(big4)\n",
    "    BN17 = BatchNormalization()(big5)\n",
    "    big6 = Conv2D(u,(64, 64), activation='relu',padding='same')(BN17)\n",
    "    BN18 = BatchNormalization()(big6)\n",
    "    big7 = Dropout(0.2)(BN18)\n",
    "    \n",
    "    big8 = Conv2D(u,(64, 64), activation='relu',padding='same')(big7)\n",
    "    BN19 = BatchNormalization()(big8)\n",
    "    big9 = Conv2D(u,(64, 64), activation='relu',padding='same')(BN19)\n",
    "    BN20 = BatchNormalization()(big9)\n",
    "    big10 = MaxPooling2D((2,2))(BN20)\n",
    "    big11 = Dropout(0.2)(big10)\n",
    "\n",
    "    concat1 = tf.keras.layers.Concatenate()([small11,med11,big11])\n",
    "\n",
    "    FC1 = Conv2D(u2,(1,1), activation='relu',padding='valid')(concat1)\n",
    "    BN21 = BatchNormalization()(FC1)\n",
    "    FC2 = Conv2D(u,(5,5), activation='relu',padding='valid')(BN21)\n",
    "    BN22 = BatchNormalization()(FC2)\n",
    "    FC3 = Conv2D(u,(5,5), activation='relu',padding='valid')(BN22)\n",
    "    BN23 = BatchNormalization()(FC3)\n",
    "    FC4 = Conv2D(u,(5,5), activation='relu',padding='valid')(BN23)\n",
    "    BN24 = BatchNormalization()(FC4)\n",
    "\n",
    "    \n",
    "    flat = Flatten()(BN24)\n",
    "\n",
    "    dense1 = keras.layers.Dense(u3, activation='relu')(flat)\n",
    "    BN25 = BatchNormalization()(dense1)\n",
    "    dense2 = keras.layers.Dense(u3, activation='relu')(BN25)\n",
    "    BN26 = BatchNormalization()(dense2)\n",
    "    dense3 = keras.layers.Dense(u3, activation='relu')(BN26)\n",
    "    BN27 = BatchNormalization()(dense3)\n",
    "    dense4 = keras.layers.Dense(u3, activation='relu')(BN27)\n",
    "    BN28 = BatchNormalization()(dense4)\n",
    "    dense5 = keras.layers.Dense(u3, activation='relu')(BN28)\n",
    "    BN29 = BatchNormalization()(dense5)\n",
    "    out1 = keras.layers.Dense(1, activation='linear')(BN29)\n",
    "\n",
    "    model = Model(inputs=[in1], outputs=[out1])\n",
    "\n",
    "    model.compile(loss=\"MeanAbsoluteError\", \n",
    "              optimizer =keras.optimizers.Adam(learning_rate=lr),\n",
    "              metrics=[tf.keras.metrics.MeanAbsoluteError(),tf.keras.metrics.MeanSquaredError()])\n",
    "\n",
    "    return model\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
