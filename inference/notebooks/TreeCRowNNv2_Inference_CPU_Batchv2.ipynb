{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f12ecab",
   "metadata": {},
   "source": [
    "## Set Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a2df03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = r'C:/Users/Path_to_image_for_inference.tif'\n",
    "\n",
    "out_path = r'C:/Users/Path_to_folder_for_output/' #inference output is full FSD map\n",
    "site = \"newV1_2019ort_\" #give descriptive name for output\n",
    "\n",
    "mod = \"v1\" #enter \"v1\" for original model, or \"v2\" for updated model with padding\n",
    "path_to_weights = r'C:/Users/Path_to_model_weights/'\n",
    "\n",
    "rgba_out = r'C:/Users/Path_to_folder_for_output_tiles/' #output are stacked image tiles RGB+heatmap\n",
    "#rgba tiles are saved to folders labeled with predicted tree count\n",
    "\n",
    "NoData = -9999 #enter NoData value of the incoming img\n",
    "tile_size = 128 #enter desired tile size between 64 - 128, default 128\n",
    "batch_size = 100 #enter batch size, max 250, default 100\n",
    "\n",
    "minval = 0 #enter min val for normalization, default 0\n",
    "maxval = 255 #enter max val for normalization, default 255\n",
    "\n",
    "generate_heatmap = True #enter 'False' or 'True'\n",
    "heatmap_algo = \"cgc\" #enter 'gc' for Grad-CAM, 'cgc' for custom Grad-CAM, or 'gcpp' for Grad-CAM++\n",
    "target_layer1 = \"batch_normalization_23\" #conv layer you want to view activations for\n",
    "target_layer2 = \"batch_normalization_13\" #conv layer you want to view activations for\n",
    "           \n",
    "normalize_heatmap = \"local\" #enter 'none', 'local', or 'global'\n",
    "generate_rgba = False #enter True to output RGB+heatmap tiles, default False\n",
    "\n",
    "from ipynb.fs.full.TreeCRowNNv2_Functions_2  import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26520d82",
   "metadata": {},
   "source": [
    "# Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c22945f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n",
      "Tensorflow ver. 2.8.0\n",
      "Device found : [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<details>\n",
       "<summary>Click to view session information</summary>\n",
       "<pre>\n",
       "-----\n",
       "PIL                 9.0.1\n",
       "cv2                 4.0.1\n",
       "ipynb               NA\n",
       "keras               2.8.0\n",
       "matplotlib          3.5.1\n",
       "numpy               1.21.5\n",
       "session_info        1.0.0\n",
       "tensorflow          2.8.0\n",
       "tifffile            2021.7.2\n",
       "-----\n",
       "</pre>\n",
       "<details>\n",
       "<summary>Click to view modules imported as dependencies</summary>\n",
       "<pre>\n",
       "aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42    NA\n",
       "absl                                        NA\n",
       "asttokens                                   NA\n",
       "astunparse                                  1.6.3\n",
       "backcall                                    0.2.0\n",
       "bottleneck                                  1.3.4\n",
       "brotli                                      NA\n",
       "certifi                                     2022.09.24\n",
       "cffi                                        1.15.0\n",
       "charset_normalizer                          2.0.12\n",
       "colorama                                    0.4.4\n",
       "cycler                                      0.10.0\n",
       "cython_runtime                              NA\n",
       "dateutil                                    2.8.2\n",
       "debugpy                                     1.5.1\n",
       "decorator                                   5.1.1\n",
       "defusedxml                                  0.7.1\n",
       "entrypoints                                 0.3\n",
       "executing                                   0.8.3\n",
       "flatbuffers                                 22.9.24\n",
       "gast                                        0.5.3\n",
       "google                                      NA\n",
       "h5py                                        3.7.0\n",
       "idna                                        3.3\n",
       "imagecodecs                                 2021.8.26\n",
       "importlib_metadata                          NA\n",
       "ipykernel                                   6.9.1\n",
       "ipython_genutils                            0.2.0\n",
       "jedi                                        0.18.1\n",
       "jupyter_server                              1.13.5\n",
       "keras_preprocessing                         1.1.2\n",
       "kiwisolver                                  1.3.2\n",
       "matplotlib_inline                           NA\n",
       "mkl                                         2.4.0\n",
       "mpl_toolkits                                NA\n",
       "nt                                          NA\n",
       "ntsecuritycon                               NA\n",
       "numexpr                                     2.8.1\n",
       "opt_einsum                                  v3.3.0\n",
       "packaging                                   21.3\n",
       "pandas                                      1.4.1\n",
       "parso                                       0.8.3\n",
       "pickleshare                                 0.7.5\n",
       "pkg_resources                               NA\n",
       "prompt_toolkit                              3.0.20\n",
       "pure_eval                                   0.2.2\n",
       "pydev_ipython                               NA\n",
       "pydevconsole                                NA\n",
       "pydevd                                      2.6.0\n",
       "pydevd_concurrency_analyser                 NA\n",
       "pydevd_file_utils                           NA\n",
       "pydevd_plugins                              NA\n",
       "pydevd_tracing                              NA\n",
       "pygments                                    2.11.2\n",
       "pyparsing                                   3.0.4\n",
       "pythoncom                                   NA\n",
       "pytz                                        2021.3\n",
       "pywintypes                                  NA\n",
       "requests                                    2.27.1\n",
       "scipy                                       1.7.3\n",
       "setuptools                                  61.2.0\n",
       "six                                         1.16.0\n",
       "socks                                       1.7.1\n",
       "stack_data                                  0.2.0\n",
       "tensorboard                                 2.8.0\n",
       "termcolor                                   NA\n",
       "tornado                                     6.1\n",
       "traitlets                                   5.1.1\n",
       "typing_extensions                           NA\n",
       "urllib3                                     1.26.9\n",
       "wcwidth                                     0.2.5\n",
       "win32api                                    NA\n",
       "win32com                                    NA\n",
       "win32security                               NA\n",
       "wrapt                                       1.14.1\n",
       "zipp                                        NA\n",
       "zmq                                         22.3.0\n",
       "</pre>\n",
       "</details> <!-- seems like this ends pre, so might as well be explicit -->\n",
       "<pre>\n",
       "-----\n",
       "IPython             8.2.0\n",
       "jupyter_client      7.1.2\n",
       "jupyter_core        4.9.2\n",
       "jupyterlab          3.3.2\n",
       "notebook            6.4.12\n",
       "-----\n",
       "Python 3.8.0 (default, Nov  6 2019, 16:00:02) [MSC v.1916 64 bit (AMD64)]\n",
       "Windows-10-10.0.19041-SP0\n",
       "-----\n",
       "Session information updated at 2023-09-18 11:29\n",
       "</pre>\n",
       "</details>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, sys, PIL,time,ipynb.fs, cv2\n",
    "import numpy as np\n",
    "import tifffile as tiff\n",
    "from PIL import Image\n",
    "Image.MAX_IMAGE_PIXELS = 5000000000\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow,figure\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "\n",
    "print(tf.__version__)\n",
    "print(f\"Tensorflow ver. {tf.__version__}\")\n",
    "physical_device = tf.config.experimental.list_physical_devices('CPU')\n",
    "print(f'Device found : {physical_device}')\n",
    "K.clear_session()\n",
    "\n",
    "from ipynb.fs.full.TreeCRowNNv2_Functions_2 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251b6e11",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8f986bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padding : 0\n"
     ]
    }
   ],
   "source": [
    "padding = int((128-tile_size)/2)\n",
    "print(f\"padding : {padding}\")\n",
    "k1=3\n",
    "k2=7\n",
    "k3=15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd27f601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 255\n",
      "47 59951 39 36391\n",
      "47 59951 39 36391\n",
      "0 255 (36430, 59998, 3)\n"
     ]
    }
   ],
   "source": [
    "image = tiff.imread(img_path)\n",
    "image[image==NoData] = 0 #np.nan #change this to nan if desired\n",
    "img = image[:,:,:3]\n",
    "print(img.min(),img.max())\n",
    "\n",
    "for i in range(0,2):\n",
    "    crop_image(img[:,:,i],tile_size)\n",
    "\n",
    "print(img.min(),img.max(),img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fdf1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img/255) #to avoid generating error, only view if the image is small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1fa5d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y,x,chan = img.shape\n",
    "big_x = round(int(x/tile_size),0)\n",
    "cropx = (big_x*tile_size)\n",
    "big_y = round(int(y/tile_size),0)\n",
    "cropy = (big_y*tile_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81079583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284, 468) (36430, 59998)\n"
     ]
    }
   ],
   "source": [
    "blank_img = np.zeros([big_y,big_x],dtype=int)\n",
    "blank_img2 = np.zeros([y,x],dtype=np.float32)\n",
    "print(blank_img.shape,blank_img2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca18453",
   "metadata": {},
   "source": [
    "## Load Model and Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3084e8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_name='TreeCRowNN'\n",
    "#architecture of model v1 and v2 are the same, only weights are different\n",
    "def tc_model(lr,spe,u,u2,u3,k1,k2,k3):\n",
    "    import time\n",
    "    import tensorflow as tf\n",
    "    from tensorflow import keras\n",
    "    from keras import backend as K\n",
    "    from keras import models,layers\n",
    "    from tensorflow.keras.layers import Input, Conv2D,Conv1D, UpSampling2D,GlobalMaxPool2D,GlobalAveragePooling2D, concatenate,Dense, Flatten, Dropout,BatchNormalization, MaxPooling2D\n",
    "    from tensorflow.keras.models import Model, Sequential, load_model\n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "    \n",
    "    in1 = Input(shape=(128,128,3))\n",
    "    \n",
    "    conv1 = Conv2D(u,(k1,k1),activation='relu', padding='same')(in1)\n",
    "    #conv1.trainable = False\n",
    "    BN1 = BatchNormalization()(conv1)\n",
    "    #BN1.trainable = False\n",
    "    conv2 = Conv2D(u,(k1,k1),activation='relu', padding='same')(BN1)\n",
    "    #conv2.trainable = False\n",
    "    BN2 = BatchNormalization()(conv2)\n",
    "    #BN2.trainable = False\n",
    " \n",
    "    small1 = Conv2D(u,(k1,k1), activation='relu', padding='same')(BN2)\n",
    "    #small1.trainable = False\n",
    "    BN3 = BatchNormalization()(small1)\n",
    "    #BN3.trainable = False\n",
    "    small2 = Conv2D(u,(k1,k1), activation='relu', padding='same')(BN3)\n",
    "    #small2.trainable = False\n",
    "    BN4 = BatchNormalization()(small2)\n",
    "    #BN4.trainable = False\n",
    "    small3 = MaxPooling2D((2,2))(BN4)\n",
    "    #small3.trainable = False\n",
    "    small4 = Dropout(0.2)(small3)\n",
    "    \n",
    "    small5 = Conv2D(u,(k1,k1), activation='relu',padding='same')(small4)\n",
    "    #small5.trainable = False\n",
    "    BN5 = BatchNormalization()(small5)\n",
    "    #BN5.trainable = False\n",
    "    small6 = Conv2D(u,(k1,k1), activation='relu',padding='same')(BN5)\n",
    "    #small6.trainable = False\n",
    "    BN6 = BatchNormalization()(small6)\n",
    "    #BN6.trainable = False\n",
    "    small7 = Dropout(0.2)(BN6)\n",
    "    \n",
    "    small8 = Conv2D(u,(k1,k1), activation='relu',padding='same')(small7)\n",
    "    #small8.trainable = False\n",
    "    BN7 = BatchNormalization()(small8)\n",
    "    #BN7.trainable = False\n",
    "    small9 = Conv2D(u,(k1,k1), activation='relu',padding='same')(BN7)\n",
    "    #small9.trainable = False\n",
    "    BN8 = BatchNormalization()(small9)\n",
    "    #BN8.trainable = False\n",
    "    small10 = MaxPooling2D((2,2))(BN8)\n",
    "    #small10.trainable = False\n",
    "    small11 = Dropout(0.2)(small10)\n",
    "\n",
    "    med1 = Conv2D(u,(k2,k2), activation='relu', padding='same')(BN2)\n",
    "    #med1.trainable = False\n",
    "    BN9 = BatchNormalization()(med1)\n",
    "    #BN9.trainable = False\n",
    "    med2 = Conv2D(u,(k2,k2), activation='relu', padding='same')(BN9)\n",
    "    #med2.trainable = False\n",
    "    BN10 = BatchNormalization()(med2)\n",
    "    #BN10.trainable = False\n",
    "    med3 = MaxPooling2D((2,2))(BN10)\n",
    "    #med3.trainable = False\n",
    "    med4 = Dropout(0.2)(med3)\n",
    "    \n",
    "    med5 = Conv2D(u,(k2,k2), activation='relu',padding='same')(med4)\n",
    "    #med5.trainable = False\n",
    "    BN11 = BatchNormalization()(med5)\n",
    "    #BN11.trainable = False\n",
    "    med6 = Conv2D(u,(k2,k2), activation='relu',padding='same')(BN11)\n",
    "    #med6.trainable = False\n",
    "    BN12 = BatchNormalization()(med6)\n",
    "    #BN12.trainable = False\n",
    "    med7 = Dropout(0.2)(BN12)\n",
    "    \n",
    "    med8 = Conv2D(u,(k2,k2), activation='relu',padding='same')(med7)\n",
    "    #med8.trainable = False\n",
    "    BN13 = BatchNormalization()(med8)\n",
    "    #BN13.trainable = False\n",
    "    med9 = Conv2D(u,(k2,k2), activation='relu',padding='same')(BN13)\n",
    "    #med9.trainable = False\n",
    "    BN14 = BatchNormalization()(med9)\n",
    "    #BN14.trainable = False\n",
    "    med10 = MaxPooling2D((2,2))(BN14)\n",
    "    #med10.trainable = False\n",
    "    med11 = Dropout(0.2)(med10)\n",
    "\n",
    "    big1 = Conv2D(u,(k3,k3), activation='relu', padding='same')(BN2)\n",
    "    #big1.trainable = False\n",
    "    BN15 = BatchNormalization()(big1)\n",
    "    #BN15.trainable = False\n",
    "    big2 = Conv2D(u,(k3,k3), activation='relu', padding='same')(BN15)\n",
    "    #big2.trainable = False\n",
    "    BN16 = BatchNormalization()(big2)\n",
    "    #BN16.trainable = False\n",
    "    big3 = MaxPooling2D((2,2))(BN16)\n",
    "    #big3.trainable = False\n",
    "    big4 = Dropout(0.2)(big3)\n",
    "    \n",
    "    big5 = Conv2D(u,(k3,k3), activation='relu',padding='same')(big4)\n",
    "    #big5.trainable = False\n",
    "    BN17 = BatchNormalization()(big5)\n",
    "    #BN17.trainable = False\n",
    "    big6 = Conv2D(u,(k3,k3), activation='relu',padding='same')(BN17)\n",
    "    #big6.trainable = False\n",
    "    BN18 = BatchNormalization()(big6)\n",
    "    #BN18.trainable = False\n",
    "    big7 = Dropout(0.2)(BN18)\n",
    "    \n",
    "    big8 = Conv2D(u,(k3,k3), activation='relu',padding='same')(big7)\n",
    "    #big8.trainable = False\n",
    "    BN19 = BatchNormalization()(big8)\n",
    "    #BN19.trainable = False\n",
    "    big9 = Conv2D(u,(k3,k3), activation='relu',padding='same')(BN19)\n",
    "    #big9.trainable = False\n",
    "    BN20 = BatchNormalization()(big9)\n",
    "    #BN20.trainable = False\n",
    "    big10 = MaxPooling2D((2,2))(BN20)\n",
    "    #big10.trainable = False\n",
    "    big11 = Dropout(0.2)(big10)\n",
    "\n",
    "    concat1 = tf.keras.layers.Concatenate()([small11,med11,big11])\n",
    "\n",
    "    FC1 = Conv2D(u2,(1,1), activation='relu',padding='valid')(concat1)\n",
    "    BN21 = BatchNormalization()(FC1)\n",
    "    FC2 = Conv2D(u,(5,5), activation='relu',padding='valid')(BN21)\n",
    "    BN22 = BatchNormalization()(FC2)\n",
    "    FC3 = Conv2D(u,(5,5), activation='relu',padding='valid')(BN22)\n",
    "    BN23 = BatchNormalization()(FC3)\n",
    "    FC4 = Conv2D(u,(5,5), activation='relu',padding='valid')(BN23)\n",
    "    BN24 = BatchNormalization()(FC4)\n",
    "\n",
    "    \n",
    "    flat = Flatten()(BN24)\n",
    "\n",
    "    dense1 = keras.layers.Dense(u3, activation='relu')(flat)\n",
    "    BN25 = BatchNormalization()(dense1)\n",
    "    dense2 = keras.layers.Dense(u3, activation='relu')(BN25)\n",
    "    BN26 = BatchNormalization()(dense2)\n",
    "    dense3 = keras.layers.Dense(u3, activation='relu')(BN26)\n",
    "    BN27 = BatchNormalization()(dense3)\n",
    "    dense4 = keras.layers.Dense(u3, activation='relu')(BN27)\n",
    "    BN28 = BatchNormalization()(dense4)\n",
    "    dense5 = keras.layers.Dense(u3, activation='relu')(BN28)\n",
    "    BN29 = BatchNormalization()(dense5)\n",
    "    out1 = keras.layers.Dense(1, activation='linear')(BN29)\n",
    "\n",
    "    model = Model(inputs=[in1], outputs=[out1])\n",
    "\n",
    "    model.compile(loss=\"MeanAbsoluteError\", \n",
    "              optimizer =keras.optimizers.Adam(learning_rate=lr),\n",
    "              metrics=[tf.keras.metrics.MeanAbsoluteError(),tf.keras.metrics.MeanSquaredError()])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c61f403",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load best model and evaluate\n",
    "if mod = \"v1\":\n",
    "    lr,spe,u,u2,u3 = 0.001,160,16,16,16\n",
    "    weights = os.path.join(path_to_weights+\"Weights_v1.h5\")\n",
    "if mod = \"v2\":\n",
    "    lr,spe,u,u2,u3 = 0.001,160,16,12,12\n",
    "    weights = os.path.join(path_to_weights+\"Weights_v2.h5\")\n",
    "\n",
    "model=tc_model(lr,spe,u,u2,u3,k1,k2,k3)\n",
    "model.load_weights(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ca4b69",
   "metadata": {},
   "source": [
    "## Perform Batch Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0df8aa5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL BLOCKS :  132912\n",
      "BATCH SIZE :  100\n"
     ]
    }
   ],
   "source": [
    "#tree_counts2,T2 = create_image2(img,blank_img,tile_size,model,chan,padding,minval,maxval,batch_size)\n",
    "T2 = create_image2(img,\n",
    "                   blank_img,\n",
    "                   blank_img2,\n",
    "                   tile_size,\n",
    "                   model,\n",
    "                   minval,\n",
    "                   maxval,\n",
    "                   batch_size,\n",
    "                   target_layer1,\n",
    "                   target_layer2,\n",
    "                   generate_heatmap,\n",
    "                   heatmap_algo,\n",
    "                   normalize_heatmap,\n",
    "                   generate_rgba,\n",
    "                   rgba_out)\n",
    "print((big_y*big_x),\" BLOCKS PROCESSED IN \",round(T2,3), ' SECONDS')\n",
    "print(\"TOTAL TIME PER BLOCK : \", (T2/(big_y*big_x)),\"sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee39bf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_trees = str(np.ndarray.sum(blank_img))\n",
    "m = tile_size/10\n",
    "area = round(((big_y*big_x)*(m*m)),2)\n",
    "print(\"TOTAL TREES PREDICTED WITH TILE SIZE \" +str(tile_size)+\" : \" + total_trees)  \n",
    "print(\"(COL, ROW)\",blank_img.shape)\n",
    "print(\"TOTAL AREA PROCESSED : \",area, \"m2 --> \",round(area/10000,2), \"ha\")\n",
    "print(\"TOTAL PROCESSING TIME : \",round(T2/60,1),\"MINUTES\")\n",
    "print(\"PREDICTED RANGE : \",blank_img.min(),\" to \",blank_img.max(), \" TREES\")\n",
    "\n",
    "plt.imshow(blank_img) #remove this if image is very large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ec7852",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_trees = str(np.ndarray.sum(blank_img))\n",
    "plt.imshow(blank_img2) #remove this if image is very large\n",
    "print(\"TOTAL TREES PREDICTED WITH TILE SIZE \" +str(tile_size)+\" : \" + total_trees)  \n",
    "print(blank_img.shape)\n",
    "blank_img.min(),blank_img.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dad8b43",
   "metadata": {},
   "source": [
    "## Write Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ec94a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write FSD map\n",
    "tiff.imwrite(str(os.path.join(out_path+site+\"_totaltrees_\"+total_trees+'.tif')),blank_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80c745a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write activation map if requested\n",
    "if generate_heatmap == True:\n",
    "    if normalize_heatmap == \"local\":\n",
    "        tiff.imwrite(str(os.path.join(out_path+site+\"ts\"+str(tile_size)+\"_heatmap_localNorm_\"+str(heatmap_algo)+'.tif')),blank_img2)\n",
    "    elif normalize_heatmap == \"global\":\n",
    "        n_heatmap = normalize_activations(blank_img3)\n",
    "        tiff.imwrite(str(os.path.join(out_path+site+\"ts\"+str(tile_size)+\"_heatmap_globalNorm_\"+str(heatmap_algo)+'.tif')),n_heatmap)\n",
    "    elif normalize_heatmap == \"none\":\n",
    "        tiff.imwrite(str(os.path.join(out_path+site+\"ts\"+str(tile_size)+\"heatmap_noNorm_\"+str(heatmap_algo)+'.tif')),blank_img2) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
