{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7567385",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37d2d112",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(img,tile_size): #this function defines the central extent and crops input to match\n",
    "    y,x = img.shape\n",
    "    cropx = (round(int(x/tile_size),0)*tile_size)\n",
    "    cropy = (round(int(y/tile_size),0)*tile_size)\n",
    "    startx = x//2-(cropx//2)\n",
    "    starty=y//2-(cropy//2)\n",
    "    print(startx, startx+cropx, starty, starty+cropy)\n",
    "    return img[starty:starty+cropy,startx:startx+cropx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ba7eb2",
   "metadata": {},
   "source": [
    "## Tree-CRowNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7029cfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_name='TreeCRowNN'\n",
    "def tc_model(lr,spe,u,u2,u3,k1,k2,k3):\n",
    "    import time\n",
    "    import tensorflow as tf\n",
    "    from tensorflow import keras\n",
    "    from keras import backend as K\n",
    "    from keras import models,layers\n",
    "    from tensorflow.keras.layers import Input, Conv2D,Conv1D, UpSampling2D,GlobalMaxPool2D,GlobalAveragePooling2D, concatenate,Dense, Flatten, Dropout,BatchNormalization, MaxPooling2D\n",
    "    from tensorflow.keras.models import Model, Sequential, load_model\n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "    \n",
    "    in1 = Input(shape=(128,128,3))\n",
    "    \n",
    "    conv1 = Conv2D(u,(k1,k1),activation='relu', padding='same')(in1)\n",
    "    #conv1.trainable = False\n",
    "    BN1 = BatchNormalization()(conv1)\n",
    "    #BN1.trainable = False\n",
    "    conv2 = Conv2D(u,(k1,k1),activation='relu', padding='same')(BN1)\n",
    "    #conv2.trainable = False\n",
    "    BN2 = BatchNormalization()(conv2)\n",
    "    #BN2.trainable = False\n",
    " \n",
    "    small1 = Conv2D(u,(k1,k1), activation='relu', padding='same')(BN2)\n",
    "    #small1.trainable = False\n",
    "    BN3 = BatchNormalization()(small1)\n",
    "    #BN3.trainable = False\n",
    "    small2 = Conv2D(u,(k1,k1), activation='relu', padding='same')(BN3)\n",
    "    #small2.trainable = False\n",
    "    BN4 = BatchNormalization()(small2)\n",
    "    #BN4.trainable = False\n",
    "    small3 = MaxPooling2D((2,2))(BN4)\n",
    "    #small3.trainable = False\n",
    "    small4 = Dropout(0.2)(small3)\n",
    "    \n",
    "    small5 = Conv2D(u,(k1,k1), activation='relu',padding='same')(small4)\n",
    "    #small5.trainable = False\n",
    "    BN5 = BatchNormalization()(small5)\n",
    "    #BN5.trainable = False\n",
    "    small6 = Conv2D(u,(k1,k1), activation='relu',padding='same')(BN5)\n",
    "    #small6.trainable = False\n",
    "    BN6 = BatchNormalization()(small6)\n",
    "    #BN6.trainable = False\n",
    "    small7 = Dropout(0.2)(BN6)\n",
    "    \n",
    "    small8 = Conv2D(u,(k1,k1), activation='relu',padding='same')(small7)\n",
    "    #small8.trainable = False\n",
    "    BN7 = BatchNormalization()(small8)\n",
    "    #BN7.trainable = False\n",
    "    small9 = Conv2D(u,(k1,k1), activation='relu',padding='same')(BN7)\n",
    "    #small9.trainable = False\n",
    "    BN8 = BatchNormalization()(small9)\n",
    "    #BN8.trainable = False\n",
    "    small10 = MaxPooling2D((2,2))(BN8)\n",
    "    #small10.trainable = False\n",
    "    small11 = Dropout(0.2)(small10)\n",
    "\n",
    "    med1 = Conv2D(u,(k2,k2), activation='relu', padding='same')(BN2)\n",
    "    #med1.trainable = False\n",
    "    BN9 = BatchNormalization()(med1)\n",
    "    #BN9.trainable = False\n",
    "    med2 = Conv2D(u,(k2,k2), activation='relu', padding='same')(BN9)\n",
    "    #med2.trainable = False\n",
    "    BN10 = BatchNormalization()(med2)\n",
    "    #BN10.trainable = False\n",
    "    med3 = MaxPooling2D((2,2))(BN10)\n",
    "    #med3.trainable = False\n",
    "    med4 = Dropout(0.2)(med3)\n",
    "    \n",
    "    med5 = Conv2D(u,(k2,k2), activation='relu',padding='same')(med4)\n",
    "    #med5.trainable = False\n",
    "    BN11 = BatchNormalization()(med5)\n",
    "    #BN11.trainable = False\n",
    "    med6 = Conv2D(u,(k2,k2), activation='relu',padding='same')(BN11)\n",
    "    #med6.trainable = False\n",
    "    BN12 = BatchNormalization()(med6)\n",
    "    #BN12.trainable = False\n",
    "    med7 = Dropout(0.2)(BN12)\n",
    "    \n",
    "    med8 = Conv2D(u,(k2,k2), activation='relu',padding='same')(med7)\n",
    "    #med8.trainable = False\n",
    "    BN13 = BatchNormalization()(med8)\n",
    "    #BN13.trainable = False\n",
    "    med9 = Conv2D(u,(k2,k2), activation='relu',padding='same')(BN13)\n",
    "    #med9.trainable = False\n",
    "    BN14 = BatchNormalization()(med9)\n",
    "    #BN14.trainable = False\n",
    "    med10 = MaxPooling2D((2,2))(BN14)\n",
    "    #med10.trainable = False\n",
    "    med11 = Dropout(0.2)(med10)\n",
    "\n",
    "    big1 = Conv2D(u,(k3,k3), activation='relu', padding='same')(BN2)\n",
    "    #big1.trainable = False\n",
    "    BN15 = BatchNormalization()(big1)\n",
    "    #BN15.trainable = False\n",
    "    big2 = Conv2D(u,(k3,k3), activation='relu', padding='same')(BN15)\n",
    "    #big2.trainable = False\n",
    "    BN16 = BatchNormalization()(big2)\n",
    "    #BN16.trainable = False\n",
    "    big3 = MaxPooling2D((2,2))(BN16)\n",
    "    #big3.trainable = False\n",
    "    big4 = Dropout(0.2)(big3)\n",
    "    \n",
    "    big5 = Conv2D(u,(k3,k3), activation='relu',padding='same')(big4)\n",
    "    #big5.trainable = False\n",
    "    BN17 = BatchNormalization()(big5)\n",
    "    #BN17.trainable = False\n",
    "    big6 = Conv2D(u,(k3,k3), activation='relu',padding='same')(BN17)\n",
    "    #big6.trainable = False\n",
    "    BN18 = BatchNormalization()(big6)\n",
    "    #BN18.trainable = False\n",
    "    big7 = Dropout(0.2)(BN18)\n",
    "    \n",
    "    big8 = Conv2D(u,(k3,k3), activation='relu',padding='same')(big7)\n",
    "    #big8.trainable = False\n",
    "    BN19 = BatchNormalization()(big8)\n",
    "    #BN19.trainable = False\n",
    "    big9 = Conv2D(u,(k3,k3), activation='relu',padding='same')(BN19)\n",
    "    #big9.trainable = False\n",
    "    BN20 = BatchNormalization()(big9)\n",
    "    #BN20.trainable = False\n",
    "    big10 = MaxPooling2D((2,2))(BN20)\n",
    "    #big10.trainable = False\n",
    "    big11 = Dropout(0.2)(big10)\n",
    "\n",
    "    concat1 = tf.keras.layers.Concatenate()([small11,med11,big11])\n",
    "\n",
    "    FC1 = Conv2D(u2,(1,1), activation='relu',padding='valid')(concat1)\n",
    "    BN21 = BatchNormalization()(FC1)\n",
    "    FC2 = Conv2D(u,(5,5), activation='relu',padding='valid')(BN21)\n",
    "    BN22 = BatchNormalization()(FC2)\n",
    "    FC3 = Conv2D(u,(5,5), activation='relu',padding='valid')(BN22)\n",
    "    BN23 = BatchNormalization()(FC3)\n",
    "    FC4 = Conv2D(u,(5,5), activation='relu',padding='valid')(BN23)\n",
    "    BN24 = BatchNormalization()(FC4)\n",
    "\n",
    "    \n",
    "    flat = Flatten()(BN24)\n",
    "\n",
    "    dense1 = keras.layers.Dense(u3, activation='relu')(flat)\n",
    "    BN25 = BatchNormalization()(dense1)\n",
    "    dense2 = keras.layers.Dense(u3, activation='relu')(BN25)\n",
    "    BN26 = BatchNormalization()(dense2)\n",
    "    dense3 = keras.layers.Dense(u3, activation='relu')(BN26)\n",
    "    BN27 = BatchNormalization()(dense3)\n",
    "    dense4 = keras.layers.Dense(u3, activation='relu')(BN27)\n",
    "    BN28 = BatchNormalization()(dense4)\n",
    "    dense5 = keras.layers.Dense(u3, activation='relu')(BN28)\n",
    "    BN29 = BatchNormalization()(dense5)\n",
    "    out1 = keras.layers.Dense(1, activation='linear')(BN29)\n",
    "\n",
    "    model = Model(inputs=[in1], outputs=[out1])\n",
    "\n",
    "    model.compile(loss=\"MeanAbsoluteError\", \n",
    "              optimizer =keras.optimizers.Adam(learning_rate=lr),\n",
    "              metrics=[tf.keras.metrics.MeanAbsoluteError(),tf.keras.metrics.MeanSquaredError()])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06502b51",
   "metadata": {},
   "source": [
    "## Activation Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2629b9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradcam_heatmap(model,\n",
    "                    patch,\n",
    "                    patch_tf,\n",
    "                    block,\n",
    "                    i,\n",
    "                    j,\n",
    "                    target_layer,\n",
    "                    tile_size,\n",
    "                    padding,\n",
    "                    normalize_heatmap,\n",
    "                    generate_rgba,\n",
    "                    rgba_out,\n",
    "                    pred_index=None):\n",
    "    import numpy as np\n",
    "    import tensorflow as tf\n",
    "    from tensorflow import keras\n",
    "    import cv2\n",
    "    \n",
    "    grad_model = keras.models.Model(model.inputs,[model.get_layer(target_layer).output,model.output])\n",
    "    \n",
    "    with tf.GradientTape(persistent=False) as tape:\n",
    "        last_conv_output, pred_out = grad_model(patch_tf)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(pred_out[0])\n",
    "            \n",
    "        #generate activation heatmap\n",
    "        class_channel = pred_out[:,pred_index]\n",
    "        grads = tape.gradient(class_channel, last_conv_output)\n",
    "        pooled_grads = tf.reduce_mean(grads,axis=(0,1,2))\n",
    "            \n",
    "        last_conv_output = last_conv_output[0]\n",
    "        heatmap = last_conv_output @ pooled_grads[...,tf.newaxis]\n",
    "        heatmap = tf.squeeze(heatmap)\n",
    "            \n",
    "        heatmap = cv2.resize(heatmap.numpy(),(tile_size+(2*padding),tile_size+(2*padding)))\n",
    "        if padding != 0:\n",
    "            heatmap = heatmap[padding:-padding,padding:-padding]\n",
    "        \n",
    "        if normalize_heatmap == \"local\":\n",
    "            normalize_activations(heatmap) \n",
    "        \n",
    "        blank_img2[block[0]:block[1],block[2]:block[3]]=heatmap\n",
    "        pred_out2 = int(tf.keras.backend.eval(pred_out))\n",
    "        \n",
    "        if pred_out2<0:\n",
    "            pred_out2=0\n",
    "            \n",
    "        blank_img[i,j]=pred_out2\n",
    "    \n",
    "        heatmap = heatmap[:,:, np.newaxis]\n",
    "        \n",
    "        if generate_rgba == True:\n",
    "            generate_rgba_tiles(patch,heatmap,pred_out2,i,j,padding,rgba_out)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6360fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_gradcam_heatmap(model,\n",
    "                           patch,\n",
    "                           patch_tf,\n",
    "                           block,\n",
    "                           i,\n",
    "                           j,\n",
    "                           target_layer1,\n",
    "                           target_layer2,\n",
    "                           tile_size,\n",
    "                           padding,\n",
    "                           normalize_heatmap,\n",
    "                           generate_rgba,\n",
    "                           rgba_out,\n",
    "                           pred_index=None):\n",
    "    import numpy as np\n",
    "    import tensorflow as tf\n",
    "    from tensorflow import keras\n",
    "    import cv2\n",
    "    \n",
    "    grad_model = keras.models.Model(model.inputs,[model.get_layer(target_layer1).output,\n",
    "                                                  model.get_layer(target_layer2).output,\n",
    "                                                  model.output])\n",
    "    \n",
    "    with tf.GradientTape() as tape1:\n",
    "        with tf.GradientTape() as tape2:\n",
    "                \n",
    "            conv1_out,conv2_out,pred_out = grad_model(patch_tf)\n",
    "            if pred_index is None:\n",
    "                pred_index = tf.argmax(pred_out[0])\n",
    "            \n",
    "            #generate activation heatmap\n",
    "            class_channel = pred_out[:,pred_index]\n",
    "                \n",
    "        conv2_grad = tape2.gradient(class_channel, conv2_out)\n",
    "    conv1_grad = tape1.gradient(class_channel, conv1_out)\n",
    "        \n",
    "    c1_pooled_grads = tf.reduce_mean(conv1_grad,axis=(0,1,2))\n",
    "    c2_pooled_grads = tf.reduce_mean(conv2_grad,axis=(0,1,2))\n",
    "            \n",
    "    c1_out = conv1_out[0]\n",
    "    c2_out = conv2_out[0]\n",
    "        \n",
    "    c1_heatmap = c1_out @ c1_pooled_grads[...,tf.newaxis]\n",
    "    c2_heatmap = c2_out @ c2_pooled_grads[...,tf.newaxis]\n",
    "        \n",
    "    c1_heatmap = tf.squeeze(c1_heatmap)\n",
    "    c2_heatmap = tf.squeeze(c2_heatmap)\n",
    "            \n",
    "    c1_heatmap = cv2.resize(c1_heatmap.numpy(),(tile_size+(2*padding),tile_size+(2*padding)))\n",
    "    c2_heatmap = cv2.resize(c2_heatmap.numpy(),(tile_size+(2*padding),tile_size+(2*padding)))\n",
    "    \n",
    "    if padding != 0:\n",
    "        c1_heatmap = c1_heatmap[padding:-padding,padding:-padding]\n",
    "        c2_heatmap = c2_heatmap[padding:-padding,padding:-padding]\n",
    "        \n",
    "    if normalize_heatmap == \"local\":\n",
    "        normalize_activations(c1_heatmap)\n",
    "        normalize_activations(c2_heatmap) \n",
    "        \n",
    "    add_heatmap = (c1_heatmap + (c2_heatmap*3))\n",
    "        \n",
    "    blank_img2[block[0]:block[1],block[2]:block[3]]=add_heatmap\n",
    "    pred_out2 = int(tf.keras.backend.eval(pred_out))\n",
    "    \n",
    "    if pred_out2<0:\n",
    "            pred_out2=0\n",
    "            \n",
    "    blank_img[i,j]=pred_out2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094d5dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/samson6460/tf_keras_gradcamplusplus/blob/master/gradcam.py\n",
    "#def gcplus_heatmap(in1, model, last_conv,tile_size,padding,normalize_heatmap,pred_index=None):\n",
    "#grad_model = keras.models.Model(model.inputs,[model.get_layer(last_conv).output,model.output])\n",
    "def gcplus_heatmap(model,\n",
    "                   patch,\n",
    "                   img,\n",
    "                   block,\n",
    "                   i,\n",
    "                   j,\n",
    "                   layer_name,\n",
    "                   tile_size,\n",
    "                   padding,\n",
    "                   normalize_heatmap,\n",
    "                   generate_rgba,\n",
    "                   rgba_out,\n",
    "                   pred_index=None):\n",
    "    \n",
    "    conv_layer = model.get_layer(layer_name)\n",
    "    grad_model = keras.models.Model([model.inputs],[conv_layer.output,model.output])\n",
    "\n",
    "    with tf.GradientTape() as gtape:\n",
    "        conv_output, pred_out = grad_model(img,training=False)\n",
    "                \n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(pred_out[0])\n",
    "                \n",
    "            #generate activation heatmap\n",
    "        if pred_index is not None:\n",
    "            pass\n",
    "        class_channel = pred_out[:,pred_index]\n",
    "                \n",
    "    grad = gtape.gradient(class_channel,conv_output)\n",
    "    \n",
    "    score_values = sum(tf.math.exp(o) for o in class_channel)\n",
    "    \n",
    "    score_values = tf.reshape(score_values, score_values.shape + (1, ) * (grad.ndim - 1))\n",
    "    \n",
    "    first_derivative = score_values*grad\n",
    "    second_derivative = first_derivative*grad\n",
    "    third_derivative = second_derivative*grad\n",
    "    \n",
    "    global_sum = np.sum(conv_output, \n",
    "                        axis=tuple(np.arange(len(conv_output.shape))[1:-1]),\n",
    "                        keepdims=True)\n",
    "    \n",
    "    alpha_denom = second_derivative*2.0 + third_derivative*global_sum\n",
    "    alpha_denom = np.where(alpha_denom != 0.0, alpha_denom, 1e-10)\n",
    "    alpha_denom = alpha_denom + tf.cast((second_derivative == 0.0), second_derivative.dtype)\n",
    "    \n",
    "    alphas = second_derivative/alpha_denom\n",
    "    \n",
    "    alpha_normalization_constant = K.sum(alphas, \n",
    "                                          axis=tuple(np.arange(len(alphas.shape))[1:-1]),\n",
    "                                          keepdims=True)\n",
    "    \n",
    "    alpha_normalization_constant = alpha_normalization_constant + tf.cast(\n",
    "    (alpha_normalization_constant == 0.0), alpha_normalization_constant.dtype)\n",
    "    \n",
    "    alsphas = alphas / alpha_normalization_constant\n",
    "\n",
    "    weights = first_derivative\n",
    "\n",
    "    deep_linearization_weights = weights * alphas\n",
    "    grad_cam_map = K.sum(deep_linearization_weights,\n",
    "                         axis=tuple(np.arange(len(deep_linearization_weights.shape))[1:-1]),\n",
    "                         keepdims=True)\n",
    "    \n",
    "    cam = K.sum(deep_linearization_weights * conv_output, axis=-1)\n",
    "\n",
    "    heatmap = np.maximum(cam, 0)\n",
    "    max_heat = np.max(heatmap)\n",
    "    if max_heat == 0:\n",
    "        max_heat = 1e-10\n",
    "    heatmap /= max_heat\n",
    "    \n",
    "    heatmap = tf.squeeze(heatmap) \n",
    "    heatmap = cv2.resize(heatmap.numpy(),(tile_size+(2*padding),tile_size+(2*padding)))\n",
    "    \n",
    "    if padding != 0:\n",
    "        heatmap = heatmap[padding:-padding,padding:-padding]\n",
    "    \n",
    "    if normalize_heatmap == \"local\":\n",
    "        normalize_activations(heatmap)\n",
    "    \n",
    "    blank_img2[block[0]:block[1],block[2]:block[3]]=heatmap\n",
    "    pred_out2 = int(tf.keras.backend.eval(pred_out))\n",
    "    \n",
    "    if pred_out2<0:\n",
    "            pred_out2=0\n",
    "    \n",
    "    blank_img[i,j]=pred_out2\n",
    "    \n",
    "    heatmap = heatmap[:,:, np.newaxis]\n",
    "    \n",
    "    if generate_rgba == True:\n",
    "        generate_rgba_tiles(patch,heatmap,pred_out2,i,j,padding,rgba_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edff93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_activations(heatmap):\n",
    "    import numpy as np\n",
    "    numer = heatmap-np.min(heatmap)\n",
    "    denom = (heatmap.max()-heatmap.min())+1e-8\n",
    "    heatmapN = numer/denom \n",
    "    return heatmapN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173b9fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_rgba_tiles(patch,heatmap,pred_out2,i,j,padding,rgba_out):\n",
    "    rgba = [patch,heatmap]\n",
    "    rgba_arr=np.dstack(rgba)\n",
    "    out_path_join = os.path.join(str(rgba_out),str(pred_out2))\n",
    "    isExist = os.path.exists(out_path_join)\n",
    "    if not isExist:\n",
    "        os.makedirs(out_path_join)\n",
    "    img_name = str(pred_out2)+\"_\"+str(i)+\"_\"+str(j)+'pad'+str(padding)+'.png'\n",
    "    cv2.imwrite(os.path.join(out_path_join,img_name),rgba_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cad4ff3",
   "metadata": {},
   "source": [
    "## Batch Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4197a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_predict(row_list,col_list,batch_size,z,tile_size):\n",
    "    n = 0\n",
    "    dataset = []\n",
    "    coords = []\n",
    "    \n",
    "    for i in row_list:\n",
    "        for j in col_list:\n",
    "                \n",
    "            row_start = i\n",
    "            row_start = row_start*tile_size\n",
    "            row_end = row_start + tile_size\n",
    "            col_start = j\n",
    "            col_start = col_start*tile_size\n",
    "            col_end = col_start + tile_size\n",
    "            \n",
    "            block = np.array([row_start,row_end,col_start,col_end]).astype('int32')\n",
    "        \n",
    "            patch = img[row_start:row_end,col_start:col_end]\n",
    "            patch_tf = tf.cast(patch,tf.float32)/maxval\n",
    "            patch_tf = tf.reshape(patch_tf, shape=[1, tile_size, tile_size, z])\n",
    "            patch_tf = tf.keras.layers.ZeroPadding2D(padding=padding)(patch_tf)\n",
    "    \n",
    "            coords.append([i,j])\n",
    "            dataset.append(patch_tf)\n",
    "            n+=1\n",
    "            if len(dataset)>=batch_size:\n",
    "                dataset2 = tf.data.Dataset.from_tensor_slices(dataset)\n",
    "                result = model.predict(dataset2)\n",
    "                for k in range (len(result)):\n",
    "                    predict = get_predict(result[k])\n",
    "                    blank_img[coords[k][0],coords[k][1]]=predict\n",
    "                coords=[]\n",
    "                dataset = []\n",
    "            if str(n)[-4:]=='0000':\n",
    "                t2 = time.time()-t1\n",
    "                print('{} pixels processed in {}, {}% done'.format(n,t2,str(\"%.2f\"%(n/total_blocks*100))))\n",
    "    print(\"FINAL PIXELS\")\n",
    "    if len(dataset)>0:\n",
    "        dataset2 = tf.data.Dataset.from_tensor_slices(dataset)\n",
    "        result = model.predict(dataset2)\n",
    "        for k in range (len(result)):\n",
    "            predict = get_predict(result[k])\n",
    "            blank_img[coords[k][0],coords[k][1]]=predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee47483c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_predict_with_heatmap(row_list,col_list,batch_size,z,tile_size):\n",
    "    n = 0\n",
    "    dataset = []\n",
    "    coords = []\n",
    "    \n",
    "    for i in row_list:\n",
    "        for j in col_list:\n",
    "                \n",
    "            row_start = i\n",
    "            row_start = row_start*tile_size\n",
    "            row_end = row_start + tile_size\n",
    "            col_start = j\n",
    "            col_start = col_start*tile_size\n",
    "            col_end = col_start + tile_size\n",
    "            \n",
    "            block = np.array([row_start,row_end,col_start,col_end]).astype('int32')\n",
    "        \n",
    "            patch = img[row_start:row_end,col_start:col_end]\n",
    "            patch_tf = tf.cast(patch,tf.float32)/maxval\n",
    "            patch_tf = tf.reshape(patch_tf, shape=[1, tile_size, tile_size, z])\n",
    "            patch_tf = tf.keras.layers.ZeroPadding2D(padding=padding)(patch_tf)\n",
    "            \n",
    "            if heatmap_algo == \"gc\":\n",
    "                gradcam_heatmap(model,\n",
    "                                    patch,\n",
    "                                    patch_tf,\n",
    "                                    block,\n",
    "                                    i,\n",
    "                                    j,\n",
    "                                    target_layer1,\n",
    "                                    tile_size,\n",
    "                                    padding,\n",
    "                                    normalize_heatmap,\n",
    "                                    generate_rgba,\n",
    "                                    rgba_out,\n",
    "                                    pred_index=None)\n",
    "                \n",
    "            elif heatmap_algo == 'cgc':\n",
    "                custom_gradcam_heatmap(model,\n",
    "                                           patch,\n",
    "                                           patch_tf,\n",
    "                                           block,\n",
    "                                           i,\n",
    "                                           j,\n",
    "                                           target_layer1,\n",
    "                                           target_layer2,\n",
    "                                           tile_size,\n",
    "                                           padding,\n",
    "                                           normalize_heatmap,\n",
    "                                           generate_rgba,\n",
    "                                           rgba_out,\n",
    "                                           pred_index=None)\n",
    "                \n",
    "                \n",
    "                \n",
    "            elif heatmap_algo == 'gcpp':   \n",
    "                gcplus_heatmap(model,\n",
    "                                   patch,\n",
    "                                   patch_tf,\n",
    "                                   block,\n",
    "                                   i,\n",
    "                                   j,\n",
    "                                   target_layer1,\n",
    "                                   tile_size,\n",
    "                                   padding,\n",
    "                                   normalize_heatmap,\n",
    "                                   generate_rgba,\n",
    "                                   rgba_out,\n",
    "                                   pred_index=None)\n",
    "            else:\n",
    "                print(\"INVALID ENTRY: please enter 'gc', 'cgc' or 'gcpp' in heatmap_algo variable to specify heatmap algorithm\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cf82afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predict(patch):\n",
    "    import numpy as np\n",
    "    prediction = np.mean(patch)\n",
    "    prediction = np.rint(prediction)\n",
    "    if prediction < 0.0:\n",
    "        prediction = 0.0 \n",
    "    return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d725a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image2(img,\n",
    "                  blank_img,\n",
    "                  blank_img2,\n",
    "                  tile_size,\n",
    "                  model,\n",
    "                  minval,\n",
    "                  maxval,\n",
    "                  batch_size,\n",
    "                  target_layer1,\n",
    "                  target_layer2,\n",
    "                  generate_heatmap,\n",
    "                  heatmap_algo,\n",
    "                  normalize_heatmap,\n",
    "                  generate_rgba,\n",
    "                  rgba_out):\n",
    "    import numpy as np\n",
    "    import time\n",
    "    import tensorflow as tf\n",
    "    from tensorflow import keras\n",
    "    from keras import backend as K\n",
    "    from keras import models,layers\n",
    "    from tensorflow.keras.layers import Input, Conv2D,Conv1D, UpSampling2D,GlobalMaxPool2D,GlobalAveragePooling2D, concatenate,Dense, Flatten, Dropout,BatchNormalization, MaxPooling2D\n",
    "    from tensorflow.keras.models import Model, Sequential, load_model\n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "    \n",
    "    t1 = time.time()\n",
    "    predictions = []\n",
    "        \n",
    "    y,x,z = img.shape\n",
    "    nblocks_row = int(y//tile_size)\n",
    "    nblocks_col = int(x//tile_size)\n",
    "    total_blocks = nblocks_row*nblocks_col\n",
    "    print(\"TOTAL BLOCKS : \",total_blocks)\n",
    "    print(\"BATCH SIZE : \",batch_size)\n",
    "    \n",
    "    padding = int((128-tile_size)/2)\n",
    "    row_list = range(0,nblocks_row)\n",
    "    col_list = range(0,nblocks_col)\n",
    "           \n",
    "    if generate_heatmap == True:\n",
    "        batch_predict_with_heatmap(row_list,col_list,batch_size,z,tile_size)\n",
    "    \n",
    "        \n",
    "    else:\n",
    "        batch_predict(row_list,col_list,batch_size,z,tile_size)\n",
    "    \n",
    "    t3=time.time()     \n",
    "    total_time = t3-t1\n",
    "        \n",
    "    return total_time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
